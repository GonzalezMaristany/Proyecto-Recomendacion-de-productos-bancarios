{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.8.16","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[]}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"> # # **PROYECTO: RECOMENDACIÓN DE PRODUCTOS BANCARIOS A CLIENTES**","metadata":{"id":"D5fn260e1ROr"}},{"cell_type":"markdown","source":"![](http://upload.wikimedia.org/wikipedia/commons/thumb/4/42/Santander_Argentina_Logo.png/1200px-Santander_Argentina_Logo.png)\n","metadata":{"id":"AKwpuLVv1ROu"}},{"cell_type":"markdown","source":"> # **EQUIPO DE TRABAJO**\n![](https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcQh9_i7yEc-BPq9RSjtEBNgZ4rV-rnYWPhVu3Vvoik6lCsJ8372Bm_iF1ovcYv85Mm8o98&usqp=CAU)\n\n# *  Magalí Estefanía Gonzalez\n# * Héctor Guillermo Maristany","metadata":{"id":"LCNeRBf61ROu"}},{"cell_type":"markdown","source":"**Link a GitHub:** ![images.png](data:image/png;base64,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)\n\n**https://github.com/GonzalezMaristany/Proyecto-Recomendacion-de-productos-bancarios**","metadata":{"id":"5iSCDzPy1ROw"}},{"cell_type":"markdown","source":"> # **Sección 6: DESARROLANDO UN MODELO DE MACHINE LEARNING**\n![](https://cdn-icons-png.flaticon.com/512/2103/2103652.png)","metadata":{"id":"OyIS8mr-0Xtz"}},{"cell_type":"markdown","source":"# **Se utilizarán cinco algoritmos de clasificación:**\n\n* **Logistic Regression**\n* **Multinomial NB**\n* **Random Forest Classifier**\n* **Light GBM**\n* **XGBoost**","metadata":{"id":"gW2inXaj0Xt0"}},{"cell_type":"markdown","source":"**A continuación se presentan las pros y contras de los cuatro modelos de estudio**","metadata":{"id":"0EE6oYwC0Xt0"}},{"cell_type":"markdown","source":"# **PREPARACIÓN DE LOS DATOS PARA EL MODELADO**","metadata":{"id":"qK6E35ZG0Xt1"}},{"cell_type":"markdown","source":"**IMPORTACIÓN DE LIBRERÍAS**","metadata":{"id":"VDi_hjHc1RO0"}},{"cell_type":"code","source":"import os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n        \n# Tratamiento de datos\nimport numpy as np                    \nimport pandas as pd\n!pip install prettytable\nfrom prettytable import PrettyTable\nimport warnings\n# Gráficos\nimport matplotlib as mpl              # Importar MatPlotLib\nimport matplotlib.pyplot as plt # El modulo Pyplot de Matplotlib\n!pip install seaborn\nimport seaborn as sns                 # Importar Seaborn\n#from sklearn.preprocessing import scale\n!pip install scikit-learn\nfrom sklearn import preprocessing  # Import label encoder\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.model_selection import train_test_split #para separar en train y test\nfrom sklearn.datasets import make_classification\nfrom sklearn.decomposition import PCA\nfrom sklearn.decomposition import IncrementalPCA\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import GridSearchCV\n!pip install scikit-multilearn\nfrom skmultilearn.problem_transform import BinaryRelevance\n# Modelos de Clasificacion:\n# LOGISTIC REGRESSION\nfrom sklearn.linear_model import LogisticRegression\n# MULTINOMIAL NAVES BAYES\nfrom sklearn.naive_bayes import MultinomialNB\n# LIGHT GBM\n!pip install lightgbm\nimport lightgbm as lgb\n# RANDOM FOREST\nfrom sklearn.ensemble import RandomForestClassifier\n# XGBOOST\n!pip install xgboost\nimport xgboost \nfrom xgboost import XGBClassifier\nfrom sklearn.multioutput import MultiOutputClassifier\nfrom xgboost import plot_importance\n# Métricas\nfrom sklearn import metrics\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import precision_score\nfrom sklearn.metrics import recall_score\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import jaccard_score\nfrom sklearn.metrics import precision_score\nfrom sklearn.metrics import recall_score\nfrom sklearn.metrics import f1_score\nprint('¡Librerías importadas con éxito!')","metadata":{"id":"0V56tErD1RO0","outputId":"681719a0-6930-4631-c5dd-dee35d0164e6","execution":{"iopub.status.busy":"2023-05-13T22:28:54.090592Z","iopub.execute_input":"2023-05-13T22:28:54.090872Z","iopub.status.idle":"2023-05-13T22:29:40.003572Z","shell.execute_reply.started":"2023-05-13T22:28:54.090846Z","shell.execute_reply":"2023-05-13T22:29:40.002701Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/santander-product-recommendation/test_ver2.csv.zip\n/kaggle/input/santander-product-recommendation/sample_submission.csv.zip\n/kaggle/input/santander-product-recommendation/train_ver2.csv.zip\nCollecting prettytable\n  Downloading prettytable-3.7.0-py3-none-any.whl (27 kB)\nRequirement already satisfied: wcwidth in /usr/local/lib/python3.8/site-packages (from prettytable) (0.2.6)\nInstalling collected packages: prettytable\nSuccessfully installed prettytable-3.7.0\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: You are using pip version 22.0.4; however, version 23.1.2 is available.\nYou should consider upgrading via the '/usr/local/bin/python -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n\u001b[0mCollecting seaborn\n  Downloading seaborn-0.12.2-py3-none-any.whl (293 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m293.3/293.3 KB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: pandas>=0.25 in /usr/local/lib/python3.8/site-packages (from seaborn) (2.0.0)\nRequirement already satisfied: matplotlib!=3.6.1,>=3.1 in /usr/local/lib/python3.8/site-packages (from seaborn) (3.7.1)\nRequirement already satisfied: numpy!=1.24.0,>=1.17 in /usr/local/lib/python3.8/site-packages (from seaborn) (1.23.5)\nRequirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.8/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (2.8.2)\nRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.8/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (1.0.7)\nRequirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.8/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (3.0.9)\nRequirement already satisfied: importlib-resources>=3.2.0 in /usr/local/lib/python3.8/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (5.12.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (1.4.4)\nRequirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.8/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (9.5.0)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (23.0)\nRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (0.11.0)\nRequirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.8/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (4.39.3)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.8/site-packages (from pandas>=0.25->seaborn) (2023.3)\nRequirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.8/site-packages (from pandas>=0.25->seaborn) (2023.3)\nRequirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.8/site-packages (from importlib-resources>=3.2.0->matplotlib!=3.6.1,>=3.1->seaborn) (3.15.0)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.1->seaborn) (1.16.0)\nInstalling collected packages: seaborn\nSuccessfully installed seaborn-0.12.2\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: You are using pip version 22.0.4; however, version 23.1.2 is available.\nYou should consider upgrading via the '/usr/local/bin/python -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n\u001b[0mCollecting scikit-learn\n  Downloading scikit_learn-1.2.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (9.8 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.8/9.8 MB\u001b[0m \u001b[31m52.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting joblib>=1.1.1\n  Downloading joblib-1.2.0-py3-none-any.whl (297 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m298.0/298.0 KB\u001b[0m \u001b[31m22.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.8/site-packages (from scikit-learn) (1.10.1)\nCollecting threadpoolctl>=2.0.0\n  Downloading threadpoolctl-3.1.0-py3-none-any.whl (14 kB)\nRequirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.8/site-packages (from scikit-learn) (1.23.5)\nInstalling collected packages: threadpoolctl, joblib, scikit-learn\nSuccessfully installed joblib-1.2.0 scikit-learn-1.2.2 threadpoolctl-3.1.0\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: You are using pip version 22.0.4; however, version 23.1.2 is available.\nYou should consider upgrading via the '/usr/local/bin/python -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n\u001b[0mCollecting scikit-multilearn\n  Downloading scikit_multilearn-0.2.0-py3-none-any.whl (89 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.4/89.4 KB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: scikit-multilearn\nSuccessfully installed scikit-multilearn-0.2.0\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: You are using pip version 22.0.4; however, version 23.1.2 is available.\nYou should consider upgrading via the '/usr/local/bin/python -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n\u001b[0mCollecting lightgbm\n  Downloading lightgbm-3.3.5-py3-none-manylinux1_x86_64.whl (2.0 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m21.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.8/site-packages (from lightgbm) (1.10.1)\nRequirement already satisfied: scikit-learn!=0.22.0 in /usr/local/lib/python3.8/site-packages (from lightgbm) (1.2.2)\nRequirement already satisfied: numpy in /usr/local/lib/python3.8/site-packages (from lightgbm) (1.23.5)\nRequirement already satisfied: wheel in /usr/local/lib/python3.8/site-packages (from lightgbm) (0.40.0)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/site-packages (from scikit-learn!=0.22.0->lightgbm) (3.1.0)\nRequirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.8/site-packages (from scikit-learn!=0.22.0->lightgbm) (1.2.0)\nInstalling collected packages: lightgbm\nSuccessfully installed lightgbm-3.3.5\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: You are using pip version 22.0.4; however, version 23.1.2 is available.\nYou should consider upgrading via the '/usr/local/bin/python -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n\u001b[0mCollecting xgboost\n  Downloading xgboost-1.7.5-py3-none-manylinux2014_x86_64.whl (200.3 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m200.3/200.3 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.8/site-packages (from xgboost) (1.10.1)\nRequirement already satisfied: numpy in /usr/local/lib/python3.8/site-packages (from xgboost) (1.23.5)\nInstalling collected packages: xgboost\nSuccessfully installed xgboost-1.7.5\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: You are using pip version 22.0.4; however, version 23.1.2 is available.\nYou should consider upgrading via the '/usr/local/bin/python -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n\u001b[0m¡Librerías importadas con éxito!\n","output_type":"stream"}]},{"cell_type":"markdown","source":"**LECTURA DEL DATASET**","metadata":{"id":"96ZC8cuz0Xt5"}},{"cell_type":"code","source":"#Lectura de dataset (archivo csv)\nclientes = pd.read_csv('/kaggle/input/santander-product-recommendation/train_ver2.csv.zip', header=0)\n# Muestra de las diez primeras filas del dataset\nclientes.head(10)","metadata":{"id":"bYI60Aq11RO2","outputId":"798273ba-3c69-4fbb-fbff-5fae64cec6ca","execution":{"iopub.status.busy":"2023-05-13T22:29:42.655123Z","iopub.execute_input":"2023-05-13T22:29:42.656071Z","iopub.status.idle":"2023-05-13T22:30:59.961376Z","shell.execute_reply.started":"2023-05-13T22:29:42.656030Z","shell.execute_reply":"2023-05-13T22:30:59.960466Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"/tmp/ipykernel_14/190704024.py:2: DtypeWarning: Columns (5,8,11,15) have mixed types. Specify dtype option on import or set low_memory=False.\n  clientes = pd.read_csv('/kaggle/input/santander-product-recommendation/train_ver2.csv.zip', header=0)\n","output_type":"stream"},{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"   fecha_dato  ncodpers ind_empleado pais_residencia sexo  age  fecha_alta   \n0  2015-01-28   1375586            N              ES    H   35  2015-01-12  \\\n1  2015-01-28   1050611            N              ES    V   23  2012-08-10   \n2  2015-01-28   1050612            N              ES    V   23  2012-08-10   \n3  2015-01-28   1050613            N              ES    H   22  2012-08-10   \n4  2015-01-28   1050614            N              ES    V   23  2012-08-10   \n5  2015-01-28   1050615            N              ES    H   23  2012-08-10   \n6  2015-01-28   1050616            N              ES    H   23  2012-08-10   \n7  2015-01-28   1050617            N              ES    H   23  2012-08-10   \n8  2015-01-28   1050619            N              ES    H   24  2012-08-10   \n9  2015-01-28   1050620            N              ES    H   23  2012-08-10   \n\n   ind_nuevo antiguedad  indrel  ... ind_hip_fin_ult1 ind_plan_fin_ult1   \n0        0.0          6     1.0  ...                0                 0  \\\n1        0.0         35     1.0  ...                0                 0   \n2        0.0         35     1.0  ...                0                 0   \n3        0.0         35     1.0  ...                0                 0   \n4        0.0         35     1.0  ...                0                 0   \n5        0.0         35     1.0  ...                0                 0   \n6        0.0         35     1.0  ...                0                 0   \n7        0.0         35     1.0  ...                0                 0   \n8        0.0         35     1.0  ...                0                 0   \n9        0.0         35     1.0  ...                0                 0   \n\n  ind_pres_fin_ult1 ind_reca_fin_ult1 ind_tjcr_fin_ult1 ind_valo_fin_ult1   \n0                 0                 0                 0                 0  \\\n1                 0                 0                 0                 0   \n2                 0                 0                 0                 0   \n3                 0                 0                 0                 0   \n4                 0                 0                 0                 0   \n5                 0                 0                 0                 0   \n6                 0                 0                 0                 0   \n7                 0                 0                 0                 0   \n8                 0                 0                 0                 0   \n9                 0                 0                 0                 0   \n\n  ind_viv_fin_ult1 ind_nomina_ult1  ind_nom_pens_ult1  ind_recibo_ult1  \n0                0             0.0                0.0                0  \n1                0             0.0                0.0                0  \n2                0             0.0                0.0                0  \n3                0             0.0                0.0                0  \n4                0             0.0                0.0                0  \n5                0             0.0                0.0                0  \n6                0             0.0                0.0                0  \n7                0             0.0                0.0                0  \n8                0             0.0                0.0                0  \n9                0             0.0                0.0                0  \n\n[10 rows x 48 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>fecha_dato</th>\n      <th>ncodpers</th>\n      <th>ind_empleado</th>\n      <th>pais_residencia</th>\n      <th>sexo</th>\n      <th>age</th>\n      <th>fecha_alta</th>\n      <th>ind_nuevo</th>\n      <th>antiguedad</th>\n      <th>indrel</th>\n      <th>...</th>\n      <th>ind_hip_fin_ult1</th>\n      <th>ind_plan_fin_ult1</th>\n      <th>ind_pres_fin_ult1</th>\n      <th>ind_reca_fin_ult1</th>\n      <th>ind_tjcr_fin_ult1</th>\n      <th>ind_valo_fin_ult1</th>\n      <th>ind_viv_fin_ult1</th>\n      <th>ind_nomina_ult1</th>\n      <th>ind_nom_pens_ult1</th>\n      <th>ind_recibo_ult1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2015-01-28</td>\n      <td>1375586</td>\n      <td>N</td>\n      <td>ES</td>\n      <td>H</td>\n      <td>35</td>\n      <td>2015-01-12</td>\n      <td>0.0</td>\n      <td>6</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2015-01-28</td>\n      <td>1050611</td>\n      <td>N</td>\n      <td>ES</td>\n      <td>V</td>\n      <td>23</td>\n      <td>2012-08-10</td>\n      <td>0.0</td>\n      <td>35</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2015-01-28</td>\n      <td>1050612</td>\n      <td>N</td>\n      <td>ES</td>\n      <td>V</td>\n      <td>23</td>\n      <td>2012-08-10</td>\n      <td>0.0</td>\n      <td>35</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2015-01-28</td>\n      <td>1050613</td>\n      <td>N</td>\n      <td>ES</td>\n      <td>H</td>\n      <td>22</td>\n      <td>2012-08-10</td>\n      <td>0.0</td>\n      <td>35</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2015-01-28</td>\n      <td>1050614</td>\n      <td>N</td>\n      <td>ES</td>\n      <td>V</td>\n      <td>23</td>\n      <td>2012-08-10</td>\n      <td>0.0</td>\n      <td>35</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>2015-01-28</td>\n      <td>1050615</td>\n      <td>N</td>\n      <td>ES</td>\n      <td>H</td>\n      <td>23</td>\n      <td>2012-08-10</td>\n      <td>0.0</td>\n      <td>35</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>2015-01-28</td>\n      <td>1050616</td>\n      <td>N</td>\n      <td>ES</td>\n      <td>H</td>\n      <td>23</td>\n      <td>2012-08-10</td>\n      <td>0.0</td>\n      <td>35</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>2015-01-28</td>\n      <td>1050617</td>\n      <td>N</td>\n      <td>ES</td>\n      <td>H</td>\n      <td>23</td>\n      <td>2012-08-10</td>\n      <td>0.0</td>\n      <td>35</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>2015-01-28</td>\n      <td>1050619</td>\n      <td>N</td>\n      <td>ES</td>\n      <td>H</td>\n      <td>24</td>\n      <td>2012-08-10</td>\n      <td>0.0</td>\n      <td>35</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>2015-01-28</td>\n      <td>1050620</td>\n      <td>N</td>\n      <td>ES</td>\n      <td>H</td>\n      <td>23</td>\n      <td>2012-08-10</td>\n      <td>0.0</td>\n      <td>35</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>10 rows × 48 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"**PREPROCESAMIENTO DE DATOS PARA MODELADO SEGÚN LO DEFINIDO EN LA SECCIÓN DE LIMPIEZA Y TRANSFORMACIÓN**","metadata":{}},{"cell_type":"code","source":"#PRIMER PASO: LIMPIEZA DE NULOS\n#-------------------------------\n# columnas conyuemp y ult_fec_cli_1t\nclientes.drop(['conyuemp', 'ult_fec_cli_1t'],axis=1, inplace=True)\n# columna renta\nclientes.loc[clientes[\"renta\"].isnull(),\"renta\"] = np.nanmedian(clientes.renta)\n# columna segmento\nclientes.loc[clientes[\"segmento\"].isnull(),\"segmento\"] = '02 - PARTICULARES'\n# columna canal_entrada\nclientes.loc[clientes[\"canal_entrada\"].isnull(),\"canal_entrada\"] = 'KHE'\n# columna indrel_1mes\nclientes[\"indrel_1mes\"] = clientes[\"indrel_1mes\"].map(lambda x: 5.0 if x == \"P\" else x).astype(float).fillna(0.0).astype(np.int8)\n# columna tiprel_1mes\nclientes.loc[clientes[\"tiprel_1mes\"].isnull(),\"tiprel_1mes\"] = 'I'\n# columna nomprov\nclientes.loc[clientes[\"nomprov\"].isnull(),\"nomprov\"] = 'MADRID'\n# columna cod_prov\nclientes.drop(['cod_prov'],axis=1, inplace=True)\n# columna sexo\nclientes.loc[clientes[\"sexo\"].isnull(),\"sexo\"] = 'V'\n# columna tipodom\nclientes.drop(['tipodom'],axis=1, inplace=True)\n#columna indfall\nclientes[\"indfall\"].fillna('N', inplace=True)\n# columna indext\nclientes[\"indext\"].fillna('N', inplace=True)\n# columna ind_actividad_cliente\nclientes[\"ind_actividad_cliente\"].fillna(0.0, inplace=True)\n# columna indresi\nclientes[\"indresi\"].fillna('S', inplace=True)\n# columna indrel\nclientes[\"indrel\"].fillna(1.0, inplace=True)\n# columna ind_nuevo\nclientes[\"ind_nuevo\"].fillna(0.0, inplace=True)\n# columna fecha_alta\ncust_ids = clientes[clientes.fecha_alta.isnull()]['ncodpers']\ntmp = clientes[clientes.ncodpers.isin(cust_ids)].groupby(['ncodpers', 'fecha_dato']).size().to_frame()\ntmp.reset_index(level=[0,1], inplace=True)\ntmp.columns=['ncodpers', 'fecha_dato','Count']\ntmp.drop(columns='Count', inplace=True)\ntmp = tmp.join(tmp.groupby('ncodpers')['fecha_dato'].agg(['min', 'max']), on='ncodpers')\ntmp.drop(['fecha_dato'], axis = 1, inplace=True)\ntmp.drop_duplicates(keep='first', inplace=True)\ntmp.rename(index=str, columns={\"ncodpers\": \"ncodpers\", \"min\": \"Min_fecha_dato\", \"max\":\"Max_fecha_dato\"}, inplace=True)\n# columna fecha_alta\nclientes = clientes.merge(tmp, on='ncodpers', how = 'outer')\nclientes.loc[clientes.fecha_alta.isnull(), 'fecha_alta'] = clientes.Min_fecha_dato\nclientes.drop(columns=['Min_fecha_dato', 'Max_fecha_dato'], inplace=True)\n# columna pais_residencia\nclientes.loc[clientes[\"pais_residencia\"].isnull(),\"pais_residencia\"] = 'ES'\n# columna ind_empleado\nclientes.loc[clientes[\"ind_empleado\"].isnull(),\"ind_empleado\"] = \"N\"\n# columnas ind_nomina_ult1 y ind_nom_pens_ult1\nclientes[\"ind_nomina_ult1\"].fillna(0.0, inplace=True)\nclientes[\"ind_nom_pens_ult1\"].fillna(0.0, inplace=True)\n#----------------------------------------------------------\n#SEGUNDO PASO: TRANSFORMACION DE DATOS\n#----------------------------------------------------------\n#columna age\nclientes['age'] = pd.to_numeric(clientes.age, errors='coerce')\nclientes = clientes[((clientes[\"age\"] > 15) & (clientes[\"age\"] < 100))]\n#columnas ind_ahor_fin_ult1 e ind_aval_fin_ult1\nclientes.drop(columns=['ind_ahor_fin_ult1', 'ind_aval_fin_ult1'],inplace = True)\n#variable fecha_dato\nclientes['fecha_dato'] = clientes['fecha_dato'].replace('-','',regex=True).str.strip(' ,')\nclientes['fecha_dato'] = clientes['fecha_dato'].astype(\"float64\")\n#variable fecha_alta\nclientes['fecha_alta'] = clientes['fecha_alta'].replace('-','',regex=True).str.strip(' ,')\nclientes['fecha_alta'] = clientes['fecha_alta'].astype(\"float64\")\n#variable antiguedad\nclientes[\"antiguedad\"] = pd.to_numeric(clientes[\"antiguedad\"],errors = 'coerce')\n#------------------------------------------------------------\n#TERCER PASO: TRANSFORMAMOS COLUMNAS CATEGÓRICAS A NUMÉRICAS CON LABELENCODER\n#------------------------------------------------------------\ncat_columns = clientes.select_dtypes(include='object').columns\nfrom sklearn.preprocessing import OrdinalEncoder\n\n#generacion del encoder \nle = OrdinalEncoder(handle_unknown='use_encoded_value' , #use cuando tenes valores desconocidos \n                    unknown_value=-1) # asignacion a valores desconocidos \n\n# generacion de numeros por cada categorico \nle.fit(clientes[cat_columns])\n\n#transformacion de las categoricas en train dataset\nclientes[cat_columns] = le.transform(clientes[cat_columns])\n#--------------------------------------------------------------\n#CUARTO PASO: LIMPIEZA DE OUTLIERS\n#--------------------------------------------------------------\nfrom sklearn.ensemble import IsolationForest\niso = IsolationForest(contamination=0.05) \nK =iso.fit_predict(clientes)\nK\nclientes[\"outliers\"] = K\nclientes = clientes.loc[clientes[\"outliers\"] != -1, :]\nclientes = clientes.drop(columns=['outliers']) \n#---------------------------------------------------------------\n#QUINTO PASO: BORRADO DE COLUMNAS SEGÚN LO OBTENIDO EN FEATURE SELECCION\n#----------------------------------------------------------------\nclientes.drop(columns=['pais_residencia', 'antiguedad','nomprov'],inplace = True)\nprint(\"listo\")","metadata":{"execution":{"iopub.status.busy":"2023-05-13T22:31:06.926244Z","iopub.execute_input":"2023-05-13T22:31:06.927207Z","iopub.status.idle":"2023-05-13T22:45:43.742578Z","shell.execute_reply.started":"2023-05-13T22:31:06.927166Z","shell.execute_reply":"2023-05-13T22:45:43.741513Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.8/site-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"listo\n","output_type":"stream"}]},{"cell_type":"code","source":"#chequeo que no hayan quedado nulos\nclientes.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2023-05-13T22:46:39.865339Z","iopub.execute_input":"2023-05-13T22:46:39.866184Z","iopub.status.idle":"2023-05-13T22:46:40.398254Z","shell.execute_reply.started":"2023-05-13T22:46:39.866145Z","shell.execute_reply":"2023-05-13T22:46:40.397343Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"fecha_dato               0\nncodpers                 0\nind_empleado             0\nsexo                     0\nage                      0\nfecha_alta               0\nind_nuevo                0\nindrel                   0\nindrel_1mes              0\ntiprel_1mes              0\nindresi                  0\nindext                   0\ncanal_entrada            0\nindfall                  0\nind_actividad_cliente    0\nrenta                    0\nsegmento                 0\nind_cco_fin_ult1         0\nind_cder_fin_ult1        0\nind_cno_fin_ult1         0\nind_ctju_fin_ult1        0\nind_ctma_fin_ult1        0\nind_ctop_fin_ult1        0\nind_ctpp_fin_ult1        0\nind_deco_fin_ult1        0\nind_deme_fin_ult1        0\nind_dela_fin_ult1        0\nind_ecue_fin_ult1        0\nind_fond_fin_ult1        0\nind_hip_fin_ult1         0\nind_plan_fin_ult1        0\nind_pres_fin_ult1        0\nind_reca_fin_ult1        0\nind_tjcr_fin_ult1        0\nind_valo_fin_ult1        0\nind_viv_fin_ult1         0\nind_nomina_ult1          0\nind_nom_pens_ult1        0\nind_recibo_ult1          0\ndtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"#chequeo de que todas las columnas sean numéricas\nclientes.info()","metadata":{"execution":{"iopub.status.busy":"2023-05-13T22:46:44.879866Z","iopub.execute_input":"2023-05-13T22:46:44.880809Z","iopub.status.idle":"2023-05-13T22:46:44.893736Z","shell.execute_reply.started":"2023-05-13T22:46:44.880772Z","shell.execute_reply":"2023-05-13T22:46:44.892863Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nIndex: 12833144 entries, 0 to 13647307\nData columns (total 39 columns):\n #   Column                 Dtype  \n---  ------                 -----  \n 0   fecha_dato             float64\n 1   ncodpers               int64  \n 2   ind_empleado           float64\n 3   sexo                   float64\n 4   age                    float64\n 5   fecha_alta             float64\n 6   ind_nuevo              float64\n 7   indrel                 float64\n 8   indrel_1mes            int8   \n 9   tiprel_1mes            float64\n 10  indresi                float64\n 11  indext                 float64\n 12  canal_entrada          float64\n 13  indfall                float64\n 14  ind_actividad_cliente  float64\n 15  renta                  float64\n 16  segmento               float64\n 17  ind_cco_fin_ult1       int64  \n 18  ind_cder_fin_ult1      int64  \n 19  ind_cno_fin_ult1       int64  \n 20  ind_ctju_fin_ult1      int64  \n 21  ind_ctma_fin_ult1      int64  \n 22  ind_ctop_fin_ult1      int64  \n 23  ind_ctpp_fin_ult1      int64  \n 24  ind_deco_fin_ult1      int64  \n 25  ind_deme_fin_ult1      int64  \n 26  ind_dela_fin_ult1      int64  \n 27  ind_ecue_fin_ult1      int64  \n 28  ind_fond_fin_ult1      int64  \n 29  ind_hip_fin_ult1       int64  \n 30  ind_plan_fin_ult1      int64  \n 31  ind_pres_fin_ult1      int64  \n 32  ind_reca_fin_ult1      int64  \n 33  ind_tjcr_fin_ult1      int64  \n 34  ind_valo_fin_ult1      int64  \n 35  ind_viv_fin_ult1       int64  \n 36  ind_nomina_ult1        float64\n 37  ind_nom_pens_ult1      float64\n 38  ind_recibo_ult1        int64  \ndtypes: float64(17), int64(21), int8(1)\nmemory usage: 3.7 GB\n","output_type":"stream"}]},{"cell_type":"code","source":"#se exporta a csv el dataset \nclientes.to_csv('clientes_modelado.csv',header=True,index=False)","metadata":{"id":"LNi1g6NI1RPp","execution":{"iopub.status.busy":"2023-05-13T22:46:48.046425Z","iopub.execute_input":"2023-05-13T22:46:48.046851Z","iopub.status.idle":"2023-05-13T22:50:07.978520Z","shell.execute_reply.started":"2023-05-13T22:46:48.046807Z","shell.execute_reply":"2023-05-13T22:50:07.977493Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"clientes_modelado=pd.read_csv('clientes_modelado.csv', header=0)\nclientes_modelado.head()","metadata":{"id":"Ko3Y0tUX1RPp","outputId":"2c5cf7ab-8c15-4b1b-ae25-42c7244ced82","execution":{"iopub.status.busy":"2023-05-13T00:28:22.157007Z","iopub.execute_input":"2023-05-13T00:28:22.158020Z","iopub.status.idle":"2023-05-13T00:29:03.643956Z","shell.execute_reply.started":"2023-05-13T00:28:22.157978Z","shell.execute_reply":"2023-05-13T00:29:03.642880Z"},"trusted":true},"execution_count":23,"outputs":[{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"   fecha_dato  ncodpers  ind_empleado  sexo   age  fecha_alta  ind_nuevo   \n0  20150128.0   1375586           3.0   0.0  35.0  20150112.0        0.0  \\\n1  20150228.0   1375586           3.0   0.0  35.0  20150112.0        0.0   \n2  20150328.0   1375586           3.0   0.0  35.0  20150112.0        0.0   \n3  20150428.0   1375586           3.0   0.0  35.0  20150112.0        0.0   \n4  20150528.0   1375586           3.0   0.0  35.0  20150112.0        0.0   \n\n   indrel  indrel_1mes  tiprel_1mes  ...  ind_hip_fin_ult1  ind_plan_fin_ult1   \n0     1.0            1          0.0  ...                 0                  0  \\\n1     1.0            1          0.0  ...                 0                  0   \n2     1.0            1          0.0  ...                 0                  0   \n3     1.0            1          0.0  ...                 0                  0   \n4     1.0            1          0.0  ...                 0                  0   \n\n   ind_pres_fin_ult1  ind_reca_fin_ult1  ind_tjcr_fin_ult1  ind_valo_fin_ult1   \n0                  0                  0                  0                  0  \\\n1                  0                  0                  0                  0   \n2                  0                  0                  0                  0   \n3                  0                  0                  0                  0   \n4                  0                  0                  0                  0   \n\n   ind_viv_fin_ult1  ind_nomina_ult1  ind_nom_pens_ult1  ind_recibo_ult1  \n0                 0              0.0                0.0                0  \n1                 0              0.0                0.0                0  \n2                 0              0.0                0.0                0  \n3                 0              0.0                0.0                0  \n4                 0              0.0                0.0                1  \n\n[5 rows x 39 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>fecha_dato</th>\n      <th>ncodpers</th>\n      <th>ind_empleado</th>\n      <th>sexo</th>\n      <th>age</th>\n      <th>fecha_alta</th>\n      <th>ind_nuevo</th>\n      <th>indrel</th>\n      <th>indrel_1mes</th>\n      <th>tiprel_1mes</th>\n      <th>...</th>\n      <th>ind_hip_fin_ult1</th>\n      <th>ind_plan_fin_ult1</th>\n      <th>ind_pres_fin_ult1</th>\n      <th>ind_reca_fin_ult1</th>\n      <th>ind_tjcr_fin_ult1</th>\n      <th>ind_valo_fin_ult1</th>\n      <th>ind_viv_fin_ult1</th>\n      <th>ind_nomina_ult1</th>\n      <th>ind_nom_pens_ult1</th>\n      <th>ind_recibo_ult1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>20150128.0</td>\n      <td>1375586</td>\n      <td>3.0</td>\n      <td>0.0</td>\n      <td>35.0</td>\n      <td>20150112.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>20150228.0</td>\n      <td>1375586</td>\n      <td>3.0</td>\n      <td>0.0</td>\n      <td>35.0</td>\n      <td>20150112.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>20150328.0</td>\n      <td>1375586</td>\n      <td>3.0</td>\n      <td>0.0</td>\n      <td>35.0</td>\n      <td>20150112.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>20150428.0</td>\n      <td>1375586</td>\n      <td>3.0</td>\n      <td>0.0</td>\n      <td>35.0</td>\n      <td>20150112.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>20150528.0</td>\n      <td>1375586</td>\n      <td>3.0</td>\n      <td>0.0</td>\n      <td>35.0</td>\n      <td>20150112.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 39 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"clientes_modelado.info()","metadata":{"execution":{"iopub.status.busy":"2023-05-08T19:36:51.635490Z","iopub.execute_input":"2023-05-08T19:36:51.636179Z","iopub.status.idle":"2023-05-08T19:36:51.647471Z","shell.execute_reply.started":"2023-05-08T19:36:51.636148Z","shell.execute_reply":"2023-05-08T19:36:51.646701Z"},"trusted":true},"execution_count":49,"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 12833143 entries, 0 to 12833142\nData columns (total 39 columns):\n #   Column                 Dtype  \n---  ------                 -----  \n 0   fecha_dato             float64\n 1   ncodpers               int64  \n 2   ind_empleado           float64\n 3   sexo                   float64\n 4   age                    float64\n 5   fecha_alta             float64\n 6   ind_nuevo              float64\n 7   indrel                 float64\n 8   indrel_1mes            int64  \n 9   tiprel_1mes            float64\n 10  indresi                float64\n 11  indext                 float64\n 12  canal_entrada          float64\n 13  indfall                float64\n 14  ind_actividad_cliente  float64\n 15  renta                  float64\n 16  segmento               float64\n 17  ind_cco_fin_ult1       int64  \n 18  ind_cder_fin_ult1      int64  \n 19  ind_cno_fin_ult1       int64  \n 20  ind_ctju_fin_ult1      int64  \n 21  ind_ctma_fin_ult1      int64  \n 22  ind_ctop_fin_ult1      int64  \n 23  ind_ctpp_fin_ult1      int64  \n 24  ind_deco_fin_ult1      int64  \n 25  ind_deme_fin_ult1      int64  \n 26  ind_dela_fin_ult1      int64  \n 27  ind_ecue_fin_ult1      int64  \n 28  ind_fond_fin_ult1      int64  \n 29  ind_hip_fin_ult1       int64  \n 30  ind_plan_fin_ult1      int64  \n 31  ind_pres_fin_ult1      int64  \n 32  ind_reca_fin_ult1      int64  \n 33  ind_tjcr_fin_ult1      int64  \n 34  ind_valo_fin_ult1      int64  \n 35  ind_viv_fin_ult1       int64  \n 36  ind_nomina_ult1        float64\n 37  ind_nom_pens_ult1      float64\n 38  ind_recibo_ult1        int64  \ndtypes: float64(17), int64(22)\nmemory usage: 3.7 GB\n","output_type":"stream"}]},{"cell_type":"code","source":"clientes_modelado.columns","metadata":{"id":"v6Z8LozY1RPp","outputId":"33266567-6b22-45ec-a952-5474fda23cf8","execution":{"iopub.status.busy":"2023-05-05T22:20:41.605153Z","iopub.execute_input":"2023-05-05T22:20:41.606200Z","iopub.status.idle":"2023-05-05T22:20:41.612572Z","shell.execute_reply.started":"2023-05-05T22:20:41.606157Z","shell.execute_reply":"2023-05-05T22:20:41.611776Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"Index(['fecha_dato', 'ncodpers', 'ind_empleado', 'sexo', 'age', 'fecha_alta',\n       'ind_nuevo', 'indrel', 'indrel_1mes', 'tiprel_1mes', 'indresi',\n       'indext', 'canal_entrada', 'indfall', 'ind_actividad_cliente', 'renta',\n       'segmento', 'ind_cco_fin_ult1', 'ind_cder_fin_ult1', 'ind_cno_fin_ult1',\n       'ind_ctju_fin_ult1', 'ind_ctma_fin_ult1', 'ind_ctop_fin_ult1',\n       'ind_ctpp_fin_ult1', 'ind_deco_fin_ult1', 'ind_deme_fin_ult1',\n       'ind_dela_fin_ult1', 'ind_ecue_fin_ult1', 'ind_fond_fin_ult1',\n       'ind_hip_fin_ult1', 'ind_plan_fin_ult1', 'ind_pres_fin_ult1',\n       'ind_reca_fin_ult1', 'ind_tjcr_fin_ult1', 'ind_valo_fin_ult1',\n       'ind_viv_fin_ult1', 'ind_nomina_ult1', 'ind_nom_pens_ult1',\n       'ind_recibo_ult1'],\n      dtype='object')"},"metadata":{}}]},{"cell_type":"code","source":"clientes_modelado.drop(columns=['fecha_dato'],inplace = True)","metadata":{"id":"yL074Lt90XuH","execution":{"iopub.status.busy":"2023-05-13T00:29:13.334266Z","iopub.execute_input":"2023-05-13T00:29:13.334996Z","iopub.status.idle":"2023-05-13T00:29:14.558180Z","shell.execute_reply.started":"2023-05-13T00:29:13.334961Z","shell.execute_reply":"2023-05-13T00:29:14.557071Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"clientes_modelado.columns","metadata":{"id":"pFrtLgFj1RPq","outputId":"e917a77f-2015-444d-90cb-c4003dc50428","execution":{"iopub.status.busy":"2023-05-09T14:36:48.884789Z","iopub.execute_input":"2023-05-09T14:36:48.885672Z","iopub.status.idle":"2023-05-09T14:36:48.891500Z","shell.execute_reply.started":"2023-05-09T14:36:48.885637Z","shell.execute_reply":"2023-05-09T14:36:48.890696Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"Index(['ncodpers', 'ind_empleado', 'sexo', 'age', 'fecha_alta', 'ind_nuevo',\n       'indrel', 'indrel_1mes', 'tiprel_1mes', 'indresi', 'indext',\n       'canal_entrada', 'indfall', 'ind_actividad_cliente', 'renta',\n       'segmento', 'ind_cco_fin_ult1', 'ind_cder_fin_ult1', 'ind_cno_fin_ult1',\n       'ind_ctju_fin_ult1', 'ind_ctma_fin_ult1', 'ind_ctop_fin_ult1',\n       'ind_ctpp_fin_ult1', 'ind_deco_fin_ult1', 'ind_deme_fin_ult1',\n       'ind_dela_fin_ult1', 'ind_ecue_fin_ult1', 'ind_fond_fin_ult1',\n       'ind_hip_fin_ult1', 'ind_plan_fin_ult1', 'ind_pres_fin_ult1',\n       'ind_reca_fin_ult1', 'ind_tjcr_fin_ult1', 'ind_valo_fin_ult1',\n       'ind_viv_fin_ult1', 'ind_nomina_ult1', 'ind_nom_pens_ult1',\n       'ind_recibo_ult1'],\n      dtype='object')"},"metadata":{}}]},{"cell_type":"markdown","source":"# **6.1 COMPARACIÓN DE LOS CINCO MODELOS**","metadata":{"id":"zemkDwC10XuI"}},{"cell_type":"markdown","source":"**SPLITTING DATASET INTO TRAINING AND TESTING**","metadata":{"id":"A0HRZqyt0XuJ"}},{"cell_type":"markdown","source":"**Debido a que nuestro conjunto de datos es demasiado grande y la memoria de la computadora no puede permitirnos ejecutar todo el conjunto de datos, solo usamos el 10% de los datos para evaluar los modelos.**","metadata":{"id":"z2ZUkPoB0XuJ"}},{"cell_type":"code","source":"#clientes_modelado se actualiza con una versión reducida y aleatoria del conjunto de datos original (una fracción del 10%). \n#Esto es útil para reducir el tiempo de procesamiento y entrenamiento de los modelos dado que conjunto de datos original es demasiado grande y complejo para manejarlo de manera eficiente.\nclientes_modelado=clientes_modelado.sample(frac=0.1)","metadata":{"id":"iKwkGECY0XuJ","execution":{"iopub.status.busy":"2023-05-09T14:36:55.683690Z","iopub.execute_input":"2023-05-09T14:36:55.684489Z","iopub.status.idle":"2023-05-09T14:36:56.333470Z","shell.execute_reply.started":"2023-05-09T14:36:55.684454Z","shell.execute_reply":"2023-05-09T14:36:56.332412Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"#En el contexto del aprendizaje supervisado, la variable objetivo (target variable) es la variable que se desea predecir. En este caso, la variable objetivo es Y, que abarca 22 variables binarias que representan productos financieros que un cliente podría adquirir o no. \n#Por otro lado, las variables independientes, también conocidas como variables predictoras, son las variables utilizadas para predecir la variable objetivo. En este caso, X es un conjunto de 16 variables socio-demográficas de los clientes que se utilizan para predecir las 22 variables binarias de la variable objetivo Y.\nX = clientes_modelado.iloc[:,0:16] #variables independientes\nY = clientes_modelado.iloc[:,16:38]    #target variable","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import math\n#selecting 80% Data as Train data, 20% Test Data\n#se calcula el índice que se utilizará para dividir el conjunto de datos en datos de entrenamiento y prueba. \n#La variable breakpt se establece en el valor del piso del 80% del número total de filas en clientes_modelado.\nbreakpt = math.floor(len(clientes_modelado)*0.8)\n\nXTrain_Cust = X.iloc[:breakpt,:].copy()\nXTest_Cust = X.iloc[breakpt:,:].copy()\n\nYTrain = Y.iloc[:breakpt,:].copy()\nYTest = Y.iloc[breakpt:,:].copy()\n\n#id and Product Data\n#se crean subconjuntos de los datos de producto de clientes_modelado para los datos de entrenamiento y de prueba. \n#La variable ilocPD contiene una lista de índices que se utilizarán para seleccionar las columnas de producto de clientes_modelado. \n#La variable Prod_DATA_Train contiene las primeras breakpt filas de las columnas especificadas en ilocPD. \n#La variable Prod_DATA_Test contiene las filas restantes de las columnas especificadas en ilocPD.\nilocPD = [0]+list(np.arange(16,38))\nProd_DATA_Train = clientes_modelado.iloc[:breakpt,ilocPD]\nProd_DATA_Test = clientes_modelado.iloc[breakpt:,ilocPD]\n\nprint('XTrain_Cust.shape  ',XTrain_Cust.shape)\nprint('XTest_Cust  ',XTest_Cust.shape)\nprint('YTrain  ',YTrain.shape)\nprint('YTest  ',YTest.shape)\nprint('Prod_DATA_Train  ',Prod_DATA_Train.shape)\nprint('Prod_DATA_Test  ',Prod_DATA_Test.shape)","metadata":{"execution":{"iopub.status.busy":"2023-05-09T14:37:03.680417Z","iopub.execute_input":"2023-05-09T14:37:03.681162Z","iopub.status.idle":"2023-05-09T14:37:03.720943Z","shell.execute_reply.started":"2023-05-09T14:37:03.681123Z","shell.execute_reply":"2023-05-09T14:37:03.720029Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"XTrain_Cust.shape   (205330, 16)\nXTest_Cust   (51333, 16)\nYTrain   (205330, 22)\nYTest   (51333, 22)\nProd_DATA_Train   (205330, 23)\nProd_DATA_Test   (51333, 23)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"**Se define la función que devuelve el mejor hiperparámetro para el modelo dado para cada producto**","metadata":{"id":"ykNej9dJ0XuK"}},{"cell_type":"markdown","source":"La función **return_BestParameters** se encarga de buscar los mejores hiperparámetros para un modelo y calcular las métricas de rendimiento para cada producto en los datos de entrada. La función toma tres argumentos: data que es el conjunto de datos de entrada, model que es el modelo para el cual se buscan los mejores hiperparámetros y params que es un diccionario que contiene los hiperparámetros para el modelo.\nLa función recorre las columnas de los datos de entrada y, para cada columna (excepto la columna \"ncodpers\"), ajusta el modelo usando la búsqueda en la grilla de hiperparámetros (GridSearchCV) y almacena los mejores hiperparámetros, la precisión y el puntaje de la métrica de exactitud en el diccionario correspondiente.\nFinalmente, la función devuelve los mejores hiperparámetros, la precisión y el puntaje de la métrica de exactitud para cada producto.","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import precision_score\nfrom sklearn.model_selection import GridSearchCV\n\ndef return_BestParameters(data, model, params):\n    \"\"\"\n    Busca los mejores hiperparámetros y métricas de rendimiento para cada producto en los datos de entrada.\n\n    Args:\n        data: Un DataFrame de pandas que contiene los datos de entrada.\n        model: El modelo de clasificación a utilizar.\n        params: Un diccionario de los parámetros del modelo a ajustar.\n\n    Returns:\n        Un diccionario de los mejores hiperparámetros para cada producto, un diccionario de la mejor precisión para cada producto, y un diccionario de la mejor puntuación de exactitud para cada producto.\n    \"\"\"\n    bestParams = {}\n    bestAccuracy = {}\n    bestPrecision = {}\n\n    for c in data.columns:\n        if c != \"ncodpers\":\n            print(f\"\\nProduct {c}\")\n            y_train = data[c]\n            x_train = data.drop([c, 'ncodpers'],axis=1)\n\n            clf = GridSearchCV(model, params, scoring='accuracy')\n            clf.fit(x_train, y_train)\n\n            bestParams[c] = clf.best_params_\n            bestAccuracy[c] = clf.best_score_\n\n            y_true, y_pred = y_train, clf.predict(x_train)\n            precision = precision_score(y_true, y_pred, average='binary', zero_division=0)\n            bestPrecision[c] = precision\n\n            print(f\" Accuracy: {clf.best_score_:.4f}\", f\" Precision: {precision:.4f}\")\n\n    return bestParams, bestAccuracy, bestPrecision","metadata":{"execution":{"iopub.status.busy":"2023-05-09T14:37:07.120947Z","iopub.execute_input":"2023-05-09T14:37:07.121844Z","iopub.status.idle":"2023-05-09T14:37:07.131610Z","shell.execute_reply.started":"2023-05-09T14:37:07.121808Z","shell.execute_reply":"2023-05-09T14:37:07.130868Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":"Se realiza una comparación entre diferentes modelos de clasificación utilizando una técnica de validación cruzada para encontrar los mejores hiperparámetros para cada modelo. La comparación se realiza utilizando cinco modelos diferentes: **regresión logística, Naive Bayes multinomial, Random Forest, Light Gradient Boosting Machine y XGBoost.**\nCada modelo se inicializa con sus respectivos hiperparámetros y se utiliza la función return_BestParameters para encontrar los mejores hiperparámetros y la precisión de cada modelo. Para cada modelo, se imprimen los resultados y el tiempo que tarda en ejecutarse.","metadata":{}},{"cell_type":"code","source":"#**Se aplican los modelos a cada producto y se obtiene el accuracy y la precision de cada uno y el conteo del tiempo que lleva la ejecución de cada modelo**\n\n# Modelos de Clasificacion:\n# LOGISTIC REGRESSION\nfrom sklearn.linear_model import LogisticRegression\n# MULTINOMIAL NAVES BAYES\nfrom sklearn.naive_bayes import MultinomialNB\n# LIGHT GBM\nimport lightgbm as lg\n# RANDOM FOREST\nfrom sklearn.ensemble import RandomForestClassifier\n# XGBOOST\nimport xgboost \nfrom xgboost import XGBClassifier\nfrom xgboost import plot_importance\n\nimport timeit\n#Getting Best Hyperparameters \nstart = timeit.default_timer()\n\n#1. Logistic Regression\nprint('-'*50)\nprint('LogisticRegression')\nprint('-'*50)\n#We are using solver as liblinear, because we are hypertuning penalty l1 and l2\nlogReg = LogisticRegression(solver='liblinear',max_iter=1000)\nparams = {'C':[0.1,1,10],'penalty':['l1','l2']}\nbestParams_logReg, bestAccuracy_logReg, bestPrecision_logReg = return_BestParameters(Prod_DATA_Train,logReg,params)\nstop = timeit.default_timer()\nprint('Time: ', stop - start)\nstart = timeit.default_timer()\n\n#2. Naive Bayes\nprint('-'*50)\nprint('Naive Bayes')\nprint('-'*50)\nnaiveB = MultinomialNB()\nparams = {'alpha':[0.1,1,10]}\nbestParams_nb, bestAccuracy_nb, bestPrecision_nb = return_BestParameters(Prod_DATA_Train,naiveB,params)\nstop = timeit.default_timer()\nprint('Time: ', stop - start)\nstart = timeit.default_timer()\n    \n#3. Random Forest Classifier\nprint('-'*50)\nprint('Random Forest Classifier')\nprint('-'*50)\nrf = RandomForestClassifier()\nparams = {'n_estimators':[50,100],'max_depth':[3,5]}\nbestParams_rf, bestAccuracy_rf, bestPrecision_rf = return_BestParameters(Prod_DATA_Train,rf,params)\nstop = timeit.default_timer()\nprint('Time: ', stop - start)\nstart = timeit.default_timer()\n    \n#4. Light Gradient Boosting Machine\nprint('-'*50)\nprint('LGBT')\nprint('-'*50)\nlgbb = lgb.LGBMClassifier()\nparams = {'max_depth':[3,5],'learning_rate':[0.01,0.1,1]}\nbestParams_lgbm, bestAccuracy_lgbm, bestPrecision_lbgm = return_BestParameters(Prod_DATA_Train,lgbb,params)\nstop = timeit.default_timer()\nprint('Time: ', stop - start)\nstart = timeit.default_timer()\n    \n#5.XGBoost\nprint('-'*50)\nprint('XGBoost')\nprint('-'*50)\nxgb = XGBClassifier()\nparams = {'max_depth':[3,5],'learning_rate':[0.01,0.1,1]}\nbestParams_xgb, bestAccuracy_xgb, bestPrecision_xgb = return_BestParameters(Prod_DATA_Train,xgb,params)\nstop = timeit.default_timer()\nprint('Time: ', stop - start)\nstart = timeit.default_timer()","metadata":{"execution":{"iopub.status.busy":"2023-05-09T14:37:11.604269Z","iopub.execute_input":"2023-05-09T14:37:11.605072Z","iopub.status.idle":"2023-05-09T15:40:32.490207Z","shell.execute_reply.started":"2023-05-09T14:37:11.605024Z","shell.execute_reply":"2023-05-09T15:40:32.489267Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"--------------------------------------------------\nLogisticRegression\n--------------------------------------------------\n\nProduct ind_cco_fin_ult1\n Accuracy: 0.7214  Precision: 0.7114\n\nProduct ind_cder_fin_ult1\n Accuracy: 0.9996  Precision: 0.0000\n\nProduct ind_cno_fin_ult1\n Accuracy: 0.9846  Precision: 0.8829\n\nProduct ind_ctju_fin_ult1\n Accuracy: 0.9966  Precision: 0.0000\n\nProduct ind_ctma_fin_ult1\n Accuracy: 0.9906  Precision: 0.0000\n\nProduct ind_ctop_fin_ult1\n Accuracy: 0.8767  Precision: 0.4478\n\nProduct ind_ctpp_fin_ult1\n Accuracy: 0.9707  Precision: 0.0000\n\nProduct ind_deco_fin_ult1\n Accuracy: 0.9984  Precision: 0.0000\n\nProduct ind_deme_fin_ult1\n Accuracy: 0.9987  Precision: 0.0000\n\nProduct ind_dela_fin_ult1\n Accuracy: 0.9654  Precision: 0.2742\n\nProduct ind_ecue_fin_ult1\n Accuracy: 0.9388  Precision: 0.4358\n\nProduct ind_fond_fin_ult1\n Accuracy: 0.9890  Precision: 0.0000\n\nProduct ind_hip_fin_ult1\n Accuracy: 0.9976  Precision: 0.0000\n\nProduct ind_plan_fin_ult1\n Accuracy: 0.9951  Precision: 0.0000\n\nProduct ind_pres_fin_ult1\n Accuracy: 0.9976  Precision: 0.0000\n\nProduct ind_reca_fin_ult1\n Accuracy: 0.9671  Precision: 0.1882\n\nProduct ind_tjcr_fin_ult1\n Accuracy: 0.9770  Precision: 0.2206\n\nProduct ind_valo_fin_ult1\n Accuracy: 0.9847  Precision: 0.0000\n\nProduct ind_viv_fin_ult1\n Accuracy: 0.9970  Precision: 0.0000\n\nProduct ind_nomina_ult1\n Accuracy: 0.9979  Precision: 0.9103\n\nProduct ind_nom_pens_ult1\n Accuracy: 0.9979  Precision: 1.0000\n\nProduct ind_recibo_ult1\n Accuracy: 0.9191  Precision: 0.6527\nTime:  293.0744206319998\n--------------------------------------------------\nNaive Bayes\n--------------------------------------------------\n\nProduct ind_cco_fin_ult1\n Accuracy: 0.7205  Precision: 0.7105\n\nProduct ind_cder_fin_ult1\n Accuracy: 0.9996  Precision: 0.0000\n\nProduct ind_cno_fin_ult1\n Accuracy: 0.9767  Precision: 0.9063\n\nProduct ind_ctju_fin_ult1\n Accuracy: 0.9966  Precision: 0.0000\n\nProduct ind_ctma_fin_ult1\n Accuracy: 0.9906  Precision: 0.0000\n\nProduct ind_ctop_fin_ult1\n Accuracy: 0.8765  Precision: 0.4385\n\nProduct ind_ctpp_fin_ult1\n Accuracy: 0.9707  Precision: 0.0000\n\nProduct ind_deco_fin_ult1\n Accuracy: 0.9984  Precision: 0.0000\n\nProduct ind_deme_fin_ult1\n Accuracy: 0.9987  Precision: 0.0000\n\nProduct ind_dela_fin_ult1\n Accuracy: 0.9656  Precision: 0.2308\n\nProduct ind_ecue_fin_ult1\n Accuracy: 0.9309  Precision: 0.2365\n\nProduct ind_fond_fin_ult1\n Accuracy: 0.9890  Precision: 0.0000\n\nProduct ind_hip_fin_ult1\n Accuracy: 0.9975  Precision: 0.0000\n\nProduct ind_plan_fin_ult1\n Accuracy: 0.9951  Precision: 0.0000\n\nProduct ind_pres_fin_ult1\n Accuracy: 0.9976  Precision: 0.0000\n\nProduct ind_reca_fin_ult1\n Accuracy: 0.9630  Precision: 0.1315\n\nProduct ind_tjcr_fin_ult1\n Accuracy: 0.9679  Precision: 0.1440\n\nProduct ind_valo_fin_ult1\n Accuracy: 0.9847  Precision: 0.0000\n\nProduct ind_viv_fin_ult1\n Accuracy: 0.9970  Precision: 0.0000\n\nProduct ind_nomina_ult1\n Accuracy: 0.9948  Precision: 0.8366\n\nProduct ind_nom_pens_ult1\n Accuracy: 0.9904  Precision: 0.7242\n\nProduct ind_recibo_ult1\n Accuracy: 0.9170  Precision: 0.6639\nTime:  30.641478197000197\n--------------------------------------------------\nRandom Forest Classifier\n--------------------------------------------------\n\nProduct ind_cco_fin_ult1\n Accuracy: 0.7211  Precision: 0.7106\n\nProduct ind_cder_fin_ult1\n Accuracy: 0.9996  Precision: 0.0000\n\nProduct ind_cno_fin_ult1\n Accuracy: 0.9761  Precision: 0.9195\n\nProduct ind_ctju_fin_ult1\n Accuracy: 0.9966  Precision: 0.0000\n\nProduct ind_ctma_fin_ult1\n Accuracy: 0.9906  Precision: 0.0000\n\nProduct ind_ctop_fin_ult1\n Accuracy: 0.8772  Precision: 0.0000\n\nProduct ind_ctpp_fin_ult1\n Accuracy: 0.9707  Precision: 0.0000\n\nProduct ind_deco_fin_ult1\n Accuracy: 0.9984  Precision: 0.0000\n\nProduct ind_deme_fin_ult1\n Accuracy: 0.9987  Precision: 0.0000\n\nProduct ind_dela_fin_ult1\n Accuracy: 0.9657  Precision: 0.0000\n\nProduct ind_ecue_fin_ult1\n Accuracy: 0.9392  Precision: 0.0000\n\nProduct ind_fond_fin_ult1\n Accuracy: 0.9890  Precision: 0.0000\n\nProduct ind_hip_fin_ult1\n Accuracy: 0.9976  Precision: 0.0000\n\nProduct ind_plan_fin_ult1\n Accuracy: 0.9951  Precision: 0.0000\n\nProduct ind_pres_fin_ult1\n Accuracy: 0.9976  Precision: 0.0000\n\nProduct ind_reca_fin_ult1\n Accuracy: 0.9673  Precision: 0.0000\n\nProduct ind_tjcr_fin_ult1\n Accuracy: 0.9771  Precision: 0.0000\n\nProduct ind_valo_fin_ult1\n Accuracy: 0.9847  Precision: 0.0000\n\nProduct ind_viv_fin_ult1\n Accuracy: 0.9970  Precision: 0.0000\n\nProduct ind_nomina_ult1\n Accuracy: 0.9979  Precision: 0.9134\n\nProduct ind_nom_pens_ult1\n Accuracy: 0.9979  Precision: 1.0000\n\nProduct ind_recibo_ult1\n Accuracy: 0.9161  Precision: 0.6970\nTime:  1200.1960284890001\n--------------------------------------------------\nLGBT\n--------------------------------------------------\n\nProduct ind_cco_fin_ult1\n Accuracy: 0.7232  Precision: 0.7151\n\nProduct ind_cder_fin_ult1\n Accuracy: 0.9996  Precision: 0.0000\n\nProduct ind_cno_fin_ult1\n Accuracy: 0.9849  Precision: 0.8892\n\nProduct ind_ctju_fin_ult1\n Accuracy: 0.9966  Precision: 0.0000\n\nProduct ind_ctma_fin_ult1\n Accuracy: 0.9906  Precision: 0.0000\n\nProduct ind_ctop_fin_ult1\n Accuracy: 0.8776  Precision: 0.5566\n\nProduct ind_ctpp_fin_ult1\n Accuracy: 0.9707  Precision: 0.0000\n\nProduct ind_deco_fin_ult1\n Accuracy: 0.9984  Precision: 0.0000\n\nProduct ind_deme_fin_ult1\n Accuracy: 0.9987  Precision: 0.0000\n\nProduct ind_dela_fin_ult1\n Accuracy: 0.9657  Precision: 0.0000\n\nProduct ind_ecue_fin_ult1\n Accuracy: 0.9392  Precision: 0.5459\n\nProduct ind_fond_fin_ult1\n Accuracy: 0.9890  Precision: 0.0000\n\nProduct ind_hip_fin_ult1\n Accuracy: 0.9976  Precision: 0.0000\n\nProduct ind_plan_fin_ult1\n Accuracy: 0.9951  Precision: 0.0000\n\nProduct ind_pres_fin_ult1\n Accuracy: 0.9976  Precision: 0.0000\n\nProduct ind_reca_fin_ult1\n Accuracy: 0.9673  Precision: 0.0000\n\nProduct ind_tjcr_fin_ult1\n Accuracy: 0.9771  Precision: 0.7391\n\nProduct ind_valo_fin_ult1\n Accuracy: 0.9847  Precision: 0.0000\n\nProduct ind_viv_fin_ult1\n Accuracy: 0.9970  Precision: 0.0000\n\nProduct ind_nomina_ult1\n Accuracy: 0.9979  Precision: 0.9115\n\nProduct ind_nom_pens_ult1\n Accuracy: 0.9979  Precision: 1.0000\n\nProduct ind_recibo_ult1\n Accuracy: 0.9196  Precision: 0.6666\nTime:  520.7175104099997\n--------------------------------------------------\nXGBoost\n--------------------------------------------------\n\nProduct ind_cco_fin_ult1\n Accuracy: 0.7232  Precision: 0.7151\n\nProduct ind_cder_fin_ult1\n Accuracy: 0.9996  Precision: 0.0000\n\nProduct ind_cno_fin_ult1\n Accuracy: 0.9849  Precision: 0.8898\n\nProduct ind_ctju_fin_ult1\n Accuracy: 0.9966  Precision: 0.0000\n\nProduct ind_ctma_fin_ult1\n Accuracy: 0.9906  Precision: 0.0000\n\nProduct ind_ctop_fin_ult1\n Accuracy: 0.8776  Precision: 0.5722\n\nProduct ind_ctpp_fin_ult1\n Accuracy: 0.9707  Precision: 0.0000\n\nProduct ind_deco_fin_ult1\n Accuracy: 0.9984  Precision: 0.0000\n\nProduct ind_deme_fin_ult1\n Accuracy: 0.9987  Precision: 0.0000\n\nProduct ind_dela_fin_ult1\n Accuracy: 0.9657  Precision: 0.0000\n\nProduct ind_ecue_fin_ult1\n Accuracy: 0.9394  Precision: 0.5455\n\nProduct ind_fond_fin_ult1\n Accuracy: 0.9890  Precision: 0.0000\n\nProduct ind_hip_fin_ult1\n Accuracy: 0.9976  Precision: 0.0000\n\nProduct ind_plan_fin_ult1\n Accuracy: 0.9951  Precision: 0.0000\n\nProduct ind_pres_fin_ult1\n Accuracy: 0.9976  Precision: 0.0000\n\nProduct ind_reca_fin_ult1\n Accuracy: 0.9673  Precision: 0.0000\n\nProduct ind_tjcr_fin_ult1\n Accuracy: 0.9771  Precision: 0.8421\n\nProduct ind_valo_fin_ult1\n Accuracy: 0.9847  Precision: 0.0000\n\nProduct ind_viv_fin_ult1\n Accuracy: 0.9970  Precision: 0.0000\n\nProduct ind_nomina_ult1\n Accuracy: 0.9979  Precision: 0.9121\n\nProduct ind_nom_pens_ult1\n Accuracy: 0.9979  Precision: 1.0000\n\nProduct ind_recibo_ult1\n Accuracy: 0.9196  Precision: 0.6727\nTime:  1756.2378412889998\n","output_type":"stream"}]},{"cell_type":"markdown","source":"**Se utilizan promedios de probabilidades para comparar los modelos**","metadata":{}},{"cell_type":"markdown","source":"**COMPARACIÓN DE ACCURACY**\n\nLa métrica de precisión (accuracy) es una medida utilizada para evaluar el rendimiento de un modelo de clasificación. Esta métrica mide la proporción de observaciones que se clasifican correctamente.\n\nMatemáticamente, la precisión se define como el número de predicciones correctas dividido por el número total de predicciones:\n![](https://www.mydatamodels.com/wp-content/uploads/2020/10/2.-Accuracy-formula-machine-learning-algorithms.png)\n\nEl valor de la precisión varía entre 0 y 1, donde 0 indica una precisión nula y 1 indica una precisión perfecta. Una precisión más alta indica que el modelo es mejor en la clasificación de las observaciones. Sin embargo, la precisión no siempre es la mejor métrica de rendimiento, ya que no tiene en cuenta la distribución de las clases o los costos asociados a los errores de clasificación.","metadata":{"id":"IoSqFybS0XuL"}},{"cell_type":"code","source":"import numpy as np\naccuracies = [bestAccuracy_logReg, bestAccuracy_nb, bestAccuracy_rf, bestAccuracy_lgbm, bestAccuracy_xgb]\nlabels = ['Logistic Regression', 'Naive Bayes', 'Random Forest', 'LGBM', 'XGBoost']\n\navg_accuracy = {}\nfor i, j in zip(labels, accuracies):\n    accuracy_sum = sum(j.values())\n    avg_accuracy[i] = np.mean(list(j.values()))\n\nprint(avg_accuracy)","metadata":{"id":"QeM4EjyG8dvc","execution":{"iopub.status.busy":"2023-05-09T15:42:31.679520Z","iopub.execute_input":"2023-05-09T15:42:31.680374Z","iopub.status.idle":"2023-05-09T15:42:31.687429Z","shell.execute_reply.started":"2023-05-09T15:42:31.680335Z","shell.execute_reply":"2023-05-09T15:42:31.686441Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"{'Logistic Regression': 0.9664336345483765, 'Naive Bayes': 0.9644986119904545, 'Random Forest': 0.9659683082222408, 'LGBM': 0.966637297830986, 'XGBoost': 0.9666501374727158}\n","output_type":"stream"}]},{"cell_type":"code","source":"col = avg_accuracy.keys()\nval = [i-0.96 for i in avg_accuracy.values()]\n\nprint(avg_accuracy)\n\nfig, ax = plt.subplots(figsize=(10, 5))\nax.bar(col, val, color=['teal', 'indianred', 'royalblue', 'darkviolet', 'bisque'])\nax.set_title('Accuracy difference for each model')\nplt.show()","metadata":{"id":"sY5BRVYp0XuM","outputId":"ff526c3b-0292-469a-a146-f31d3c582227","execution":{"iopub.status.busy":"2023-05-09T15:43:16.518740Z","iopub.execute_input":"2023-05-09T15:43:16.519583Z","iopub.status.idle":"2023-05-09T15:43:16.783584Z","shell.execute_reply.started":"2023-05-09T15:43:16.519547Z","shell.execute_reply":"2023-05-09T15:43:16.782772Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"{'Logistic Regression': 0.9664336345483765, 'Naive Bayes': 0.9644986119904545, 'Random Forest': 0.9659683082222408, 'LGBM': 0.966637297830986, 'XGBoost': 0.9666501374727158}\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 1000x500 with 1 Axes>","image/png":"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"},"metadata":{}}]},{"cell_type":"markdown","source":"**OBSERVACIONES:**\n* Todas los accuracy son muy buenos siendo el modelo que obtuvo el mayor valor promedio el XGBOOST.","metadata":{"id":"AfPem4SN0XuN"}},{"cell_type":"markdown","source":"**COMPARACIÓN DE PRECISION**\n\nLa precisión es una métrica utilizada para evaluar el rendimiento de un modelo de clasificación. Se define como la relación entre las predicciones positivas verdaderas y el número total de predicciones positivas. En otras palabras, la precisión mide cuántas de las predicciones positivas realizadas por el modelo son realmente correctas.\nLa precisión es particularmente útil cuando el costo de los falsos positivos es alto.\nLa precisión se calcula utilizando la siguiente fórmula:\n\n![](https://tse2.mm.bing.net/th?id=OIP.7yJ3DuGyhwp0x-pjKjJJpgHaBx&pid=Api&P=0)","metadata":{}},{"cell_type":"code","source":"import numpy as np\nprecisions = [bestPrecision_logReg, bestPrecision_nb, bestPrecision_rf, bestPrecision_lbgm, bestPrecision_xgb]\nlabels = ['Logistic Regression', 'Naive Bayes', 'Random Forest', 'LGBM', 'XGBoost']\n\navg_precision = {}\nfor i, j in zip(labels, precisions):\n    accuracy_sum = sum(j.values())\n    avg_precision[i] = np.mean(list(j.values()))\n\nprint(avg_precision)","metadata":{"execution":{"iopub.status.busy":"2023-05-09T15:44:27.636054Z","iopub.execute_input":"2023-05-09T15:44:27.636925Z","iopub.status.idle":"2023-05-09T15:44:27.644024Z","shell.execute_reply.started":"2023-05-09T15:44:27.636890Z","shell.execute_reply":"2023-05-09T15:44:27.643157Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stdout","text":"{'Logistic Regression': 0.2601817140611041, 'Naive Bayes': 0.2283066282361098, 'Random Forest': 0.19274691513218095, 'LGBM': 0.27381512392265756, 'XGBoost': 0.2795219963588116}\n","output_type":"stream"}]},{"cell_type":"code","source":"col = avg_precision.keys()\nval = avg_precision.values()\n\nprint(avg_precision)\n\nfig, ax = plt.subplots(figsize=(10, 5))\nax.bar(col, val, color=['teal', 'indianred', 'royalblue', 'darkviolet', 'bisque'])\nax.set_title('Precision difference for each model')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-05-09T15:44:31.587998Z","iopub.execute_input":"2023-05-09T15:44:31.588728Z","iopub.status.idle":"2023-05-09T15:44:31.778134Z","shell.execute_reply.started":"2023-05-09T15:44:31.588695Z","shell.execute_reply":"2023-05-09T15:44:31.777207Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stdout","text":"{'Logistic Regression': 0.2601817140611041, 'Naive Bayes': 0.2283066282361098, 'Random Forest': 0.19274691513218095, 'LGBM': 0.27381512392265756, 'XGBoost': 0.2795219963588116}\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 1000x500 with 1 Axes>","image/png":"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"},"metadata":{}}]},{"cell_type":"markdown","source":"**OBSERVACIONES:**\n* El mayor valor promedio de precision se obtiene con el modelo XGBOOST.","metadata":{}},{"cell_type":"markdown","source":"**SE GRAFICA EL TIEMPO QUE TARDA CADA ALGORITMO EN EJECUTARSE**","metadata":{"id":"PmSbKex20XuO"}},{"cell_type":"code","source":"labels = ['Logistic Regression', 'Naive Bayes', 'Random Forest', 'LGBM', 'XGBoost']\ntime = [293.07, 30.64, 1200.19, 520.71, 1756.24]\nfig, ax = plt.subplots(figsize=(10, 6))\nax.pie(time, labels=labels)\nax.set_title('Time taken for each model')\nplt.show()","metadata":{"id":"Iew5grUk8p8z","outputId":"d278ea21-752c-46a9-cf2f-f687ac77efab","execution":{"iopub.status.busy":"2023-05-09T15:45:13.291865Z","iopub.execute_input":"2023-05-09T15:45:13.292756Z","iopub.status.idle":"2023-05-09T15:45:13.418570Z","shell.execute_reply.started":"2023-05-09T15:45:13.292723Z","shell.execute_reply":"2023-05-09T15:45:13.417678Z"},"trusted":true},"execution_count":28,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 1000x600 with 1 Axes>","image/png":"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"},"metadata":{}}]},{"cell_type":"markdown","source":"**OBSERVACIONES:**\n* Random Forest tuvo el mayor tiempo de ejecución.\n* Naive bayes tiene solo 1 parámetro para sintonizar, aún así se ejecutó en el menor tiempo.\n* LGBM tiene 1 parámetro más para sintonizar que Random Forest, pero tomó menos tiempo que el mismo.\n* En general, se puede ver que los modelos basados en árboles (Random Forest, LGBM y XGBoost) tardaron más tiempo en entrenar que los modelos lineales (regresión logística y Naive Bayes). ","metadata":{"id":"dSP3OQob0XuO"}},{"cell_type":"code","source":"MatrizDecision = pd.DataFrame({'Accuracy': [0.9664, 0.9645, 0.9660, 0.9666,0.9667],\n                   'Precision': [0.2602, 0.2283, 0.1927,0.2738,0.2795],\n                   'Tiempo ejecución': [293.07, 30.64, 1200.19, 520.71, 1756.24]\n                   })\nMatrizDecision.index = ['Logistic Regression', 'Naive Bayes', 'Random Forest', 'LGBM', 'XGBoost']\n\nprint(MatrizDecision)","metadata":{"execution":{"iopub.status.busy":"2023-05-13T21:00:51.306355Z","iopub.execute_input":"2023-05-13T21:00:51.307224Z","iopub.status.idle":"2023-05-13T21:00:51.316650Z","shell.execute_reply.started":"2023-05-13T21:00:51.307192Z","shell.execute_reply":"2023-05-13T21:00:51.315836Z"},"trusted":true},"execution_count":41,"outputs":[{"name":"stdout","text":"                     Accuracy  Precision  Tiempo ejecución\nLogistic Regression    0.9664     0.2602            293.07\nNaive Bayes            0.9645     0.2283             30.64\nRandom Forest          0.9660     0.1927           1200.19\nLGBM                   0.9666     0.2738            520.71\nXGBoost                0.9667     0.2795           1756.24\n","output_type":"stream"}]},{"cell_type":"markdown","source":"**Observaciones:**\n\nLa matriz proporcionada presenta los resultados de varios modelos de clasificación, evaluados en términos de accuracy, precisión y tiempo de ejecución.\n\nEn términos de accuracy, los modelos XGBoost y Random Forest obtienen los valores más altos con 96.67% y 96.60%, respectivamente, lo que indica que son los modelos más precisos en la clasificación de los datos de prueba. Sin embargo, es importante tener en cuenta que un accuracy alto no siempre indica un modelo óptimo, ya que puede estar sobreajustado y no generalizar bien en nuevos datos.\n\nEn cuanto a la precisión, los modelos XGBoost y Random Forest obtienen los valores más altos de 0.2795 y 0.2738, respectivamente, lo que significa que son más precisos en la identificación de verdaderos positivos.\n\nEn términos de tiempo de ejecución, el modelo Naive Bayes parece ser el más rápido con un tiempo de ejecución de 30.64 segundos, seguido por Logistic Regression y LGBM con tiempos de ejecución de 293.07 y 520.71 segundos, respectivamente. Por otro lado, Random Forest y XGBoost tienen tiempos de ejecución más largos, de 1200.19 y 1756.24 segundos, respectivamente.\n\nEn conclusión, se puede afirmar que los modelos XGBoost y Random Forest son los más precisos en la clasificación de los datos de prueba, aunque el tiempo de ejecución es más largo que los otros modelos. Por otro lado, el modelo Naive Bayes es el más rápido, pero tiene una precisión y precisión relativamente bajas en comparación con los otros modelos. Por lo tanto, la elección del modelo dependerá de la priorización de la precisión o el tiempo de ejecución en el contexto específico de la aplicación.","metadata":{}},{"cell_type":"markdown","source":"**Basándonos en las observaciones obtenidas al evaluar los 5 modelos, hemos decidido utilizar dos modelos diferentes para realizar las predicciones y analizar en mayor detalle su performance: Multinomial Naive Bayes y XGBoost.**\n\n* **El modelo Multinomial Naive Bayes se eligió debido a su menor tiempo de ejecución en comparación con otros modelos evaluados. Sin embargo, se observó que este modelo tenía valores más bajos de accuracy y precision en comparación con otros modelos. Aunque este modelo puede no ser el más preciso, su velocidad de ejecución lo hace adecuado para aplicaciones en tiempo real donde el tiempo de respuesta es crítico.**\n\n* **El modelo XGBoost se eligió debido a sus mejores valores de accuracy y precision en comparación con otros modelos. Sin embargo, se observó que este modelo tuvo el mayor tiempo de ejecución en comparación con otros modelos. Este modelo es útil cuando la precisión es crítica y no hay limitaciones en el tiempo de respuesta.**","metadata":{}},{"cell_type":"markdown","source":"> # **6. 2 MULTINOMIAL NAIVE BAYES**\n![](https://static.thenounproject.com/png/1503819-200.png)","metadata":{"id":"D0UBE3Wr0XuP"}},{"cell_type":"code","source":"clientes_modelado=pd.read_csv('clientes_modelado.csv', header=0)\nclientes_modelado.head()","metadata":{"id":"k93rTQsz0XuP","outputId":"8bdaa70b-18ce-462d-c525-0a7dbc31a21c","execution":{"iopub.status.busy":"2023-05-13T20:56:43.034597Z","iopub.execute_input":"2023-05-13T20:56:43.035611Z","iopub.status.idle":"2023-05-13T20:57:23.492627Z","shell.execute_reply.started":"2023-05-13T20:56:43.035573Z","shell.execute_reply":"2023-05-13T20:57:23.491664Z"},"trusted":true},"execution_count":28,"outputs":[{"execution_count":28,"output_type":"execute_result","data":{"text/plain":"   fecha_dato  ncodpers  ind_empleado  sexo   age  fecha_alta  ind_nuevo   \n0  20150128.0   1375586           3.0   0.0  35.0  20150112.0        0.0  \\\n1  20150228.0   1375586           3.0   0.0  35.0  20150112.0        0.0   \n2  20150328.0   1375586           3.0   0.0  35.0  20150112.0        0.0   \n3  20150428.0   1375586           3.0   0.0  35.0  20150112.0        0.0   \n4  20150528.0   1375586           3.0   0.0  35.0  20150112.0        0.0   \n\n   indrel  indrel_1mes  tiprel_1mes  ...  ind_hip_fin_ult1  ind_plan_fin_ult1   \n0     1.0            1          0.0  ...                 0                  0  \\\n1     1.0            1          0.0  ...                 0                  0   \n2     1.0            1          0.0  ...                 0                  0   \n3     1.0            1          0.0  ...                 0                  0   \n4     1.0            1          0.0  ...                 0                  0   \n\n   ind_pres_fin_ult1  ind_reca_fin_ult1  ind_tjcr_fin_ult1  ind_valo_fin_ult1   \n0                  0                  0                  0                  0  \\\n1                  0                  0                  0                  0   \n2                  0                  0                  0                  0   \n3                  0                  0                  0                  0   \n4                  0                  0                  0                  0   \n\n   ind_viv_fin_ult1  ind_nomina_ult1  ind_nom_pens_ult1  ind_recibo_ult1  \n0                 0              0.0                0.0                0  \n1                 0              0.0                0.0                0  \n2                 0              0.0                0.0                0  \n3                 0              0.0                0.0                0  \n4                 0              0.0                0.0                1  \n\n[5 rows x 39 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>fecha_dato</th>\n      <th>ncodpers</th>\n      <th>ind_empleado</th>\n      <th>sexo</th>\n      <th>age</th>\n      <th>fecha_alta</th>\n      <th>ind_nuevo</th>\n      <th>indrel</th>\n      <th>indrel_1mes</th>\n      <th>tiprel_1mes</th>\n      <th>...</th>\n      <th>ind_hip_fin_ult1</th>\n      <th>ind_plan_fin_ult1</th>\n      <th>ind_pres_fin_ult1</th>\n      <th>ind_reca_fin_ult1</th>\n      <th>ind_tjcr_fin_ult1</th>\n      <th>ind_valo_fin_ult1</th>\n      <th>ind_viv_fin_ult1</th>\n      <th>ind_nomina_ult1</th>\n      <th>ind_nom_pens_ult1</th>\n      <th>ind_recibo_ult1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>20150128.0</td>\n      <td>1375586</td>\n      <td>3.0</td>\n      <td>0.0</td>\n      <td>35.0</td>\n      <td>20150112.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>20150228.0</td>\n      <td>1375586</td>\n      <td>3.0</td>\n      <td>0.0</td>\n      <td>35.0</td>\n      <td>20150112.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>20150328.0</td>\n      <td>1375586</td>\n      <td>3.0</td>\n      <td>0.0</td>\n      <td>35.0</td>\n      <td>20150112.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>20150428.0</td>\n      <td>1375586</td>\n      <td>3.0</td>\n      <td>0.0</td>\n      <td>35.0</td>\n      <td>20150112.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>20150528.0</td>\n      <td>1375586</td>\n      <td>3.0</td>\n      <td>0.0</td>\n      <td>35.0</td>\n      <td>20150112.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 39 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"clientes_modelado.drop(columns=['fecha_dato'],inplace = True)","metadata":{"id":"9W7U9v-y0XuQ","execution":{"iopub.status.busy":"2023-05-13T20:57:26.273804Z","iopub.execute_input":"2023-05-13T20:57:26.275047Z","iopub.status.idle":"2023-05-13T20:57:27.492695Z","shell.execute_reply.started":"2023-05-13T20:57:26.275004Z","shell.execute_reply":"2023-05-13T20:57:27.491464Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"#se selecciona el 70% de las filas del dataset original, es decir, se está realizando una reducción del tamaño del dataset original \n#para poder trabajar con una muestra más pequeña y eficiente.\nclientes_modelado=clientes_modelado.sample(frac=0.7)","metadata":{"execution":{"iopub.status.busy":"2023-05-13T20:57:29.404766Z","iopub.execute_input":"2023-05-13T20:57:29.405795Z","iopub.status.idle":"2023-05-13T20:57:35.440051Z","shell.execute_reply.started":"2023-05-13T20:57:29.405751Z","shell.execute_reply":"2023-05-13T20:57:35.438945Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"clientes_modelado.columns","metadata":{"id":"a2gs6h2f0XuQ","outputId":"7f671edc-dd15-4b02-e612-a5d2dd6c1ed7","execution":{"iopub.status.busy":"2023-05-13T20:57:37.883742Z","iopub.execute_input":"2023-05-13T20:57:37.884180Z","iopub.status.idle":"2023-05-13T20:57:37.891859Z","shell.execute_reply.started":"2023-05-13T20:57:37.884149Z","shell.execute_reply":"2023-05-13T20:57:37.890881Z"},"trusted":true},"execution_count":31,"outputs":[{"execution_count":31,"output_type":"execute_result","data":{"text/plain":"Index(['ncodpers', 'ind_empleado', 'sexo', 'age', 'fecha_alta', 'ind_nuevo',\n       'indrel', 'indrel_1mes', 'tiprel_1mes', 'indresi', 'indext',\n       'canal_entrada', 'indfall', 'ind_actividad_cliente', 'renta',\n       'segmento', 'ind_cco_fin_ult1', 'ind_cder_fin_ult1', 'ind_cno_fin_ult1',\n       'ind_ctju_fin_ult1', 'ind_ctma_fin_ult1', 'ind_ctop_fin_ult1',\n       'ind_ctpp_fin_ult1', 'ind_deco_fin_ult1', 'ind_deme_fin_ult1',\n       'ind_dela_fin_ult1', 'ind_ecue_fin_ult1', 'ind_fond_fin_ult1',\n       'ind_hip_fin_ult1', 'ind_plan_fin_ult1', 'ind_pres_fin_ult1',\n       'ind_reca_fin_ult1', 'ind_tjcr_fin_ult1', 'ind_valo_fin_ult1',\n       'ind_viv_fin_ult1', 'ind_nomina_ult1', 'ind_nom_pens_ult1',\n       'ind_recibo_ult1'],\n      dtype='object')"},"metadata":{}}]},{"cell_type":"markdown","source":"**TRAIN-TEST SPLIT**","metadata":{"id":"Pgwgh-Ik0XuR"}},{"cell_type":"code","source":"X = clientes_modelado.iloc[:,0:16] #variables independientes\nY = clientes_modelado.iloc[:,16:38]    #target variable","metadata":{"id":"1FX9XiSB0XuR","execution":{"iopub.status.busy":"2023-05-13T20:57:42.591239Z","iopub.execute_input":"2023-05-13T20:57:42.591665Z","iopub.status.idle":"2023-05-13T20:57:43.431104Z","shell.execute_reply.started":"2023-05-13T20:57:42.591633Z","shell.execute_reply":"2023-05-13T20:57:43.429836Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n#La función train_test_split se configura para que se utilice el 20% de los datos como conjunto de prueba (test_size=0.2) \n#y se fija la semilla aleatoria (random_state) en 42 para asegurar que los resultados sean reproducibles.\nX_train, X_test, y_train, y_test = train_test_split(X, Y,test_size=0.2,random_state=42) ","metadata":{"id":"v5Z3fzFK0XuR","execution":{"iopub.status.busy":"2023-05-13T20:57:47.673330Z","iopub.execute_input":"2023-05-13T20:57:47.673747Z","iopub.status.idle":"2023-05-13T20:57:53.796698Z","shell.execute_reply.started":"2023-05-13T20:57:47.673716Z","shell.execute_reply":"2023-05-13T20:57:53.795369Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"markdown","source":"**Para identificar qué productos podrían ser comprados por los clientes, se utilizó un clasificador de etiquetas múltiples, ya que se tenían varias variables objetivo. Para hacer predicciones, se transformó el conjunto de datos de múltiples etiquetas en un conjunto de datos de una sola etiqueta, ya que los conjuntos de datos y los problemas de una sola etiqueta son más legibles por máquina y facilitan la construcción del modelo. Se utilizó la técnica de Relevancia Binaria, que divide los problemas de múltiples etiquetas en problemas únicos de una sola clase. En otras palabras, se transformó un problema de clasificación de múltiples etiquetas con N etiquetas en N problemas de clasificación binaria separados de una sola etiqueta utilizando el mismo clasificador base. El resultado de la predicción es la unión de todos los clasificadores de una sola etiqueta.\nSe eligió MultinomialNB() como el método del algoritmo Naive Bayes utilizado para la clasificación, ya que se demostró que este algoritmo funciona bien para problemas de clasificación con múltiples clases, como el que se tenía en este caso.**","metadata":{"id":"OOS5itHM0XuR"}},{"cell_type":"code","source":"# Create a Binary Relevance classifier using MultinomialNB algorithm for multi-class classification\nbin_rel_classifier = BinaryRelevance(MultinomialNB())\n\n# The classifier cannot handle negative values, so we need to modify the instances of the _change function\n# Where a product has been dropped from the value -1 to 0, limiting us from three dimensions (dropped, unchanged, added)\n# to two dimensions (unchanged or dropped, added)\n\n# Fit the model\nbin_rel_classifier.fit(X_train, y_train)\n\n# Make predictions on the test set\ny_pred = bin_rel_classifier.predict(X_test)\n\n# Convert the sparse matrix to a dense array and create a Pandas dataframe from it\ny_pred = pd.DataFrame(y_pred.toarray())\n","metadata":{"id":"_le6UL8j0XuS","outputId":"328ba9e7-1f7e-4a70-c0a9-01ae6b467c01","execution":{"iopub.status.busy":"2023-05-13T20:57:58.025669Z","iopub.execute_input":"2023-05-13T20:57:58.026116Z","iopub.status.idle":"2023-05-13T20:59:21.852382Z","shell.execute_reply.started":"2023-05-13T20:57:58.026082Z","shell.execute_reply":"2023-05-13T20:59:21.851424Z"},"trusted":true},"execution_count":34,"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"#evaluate the model with accuracy and precision score for the test set\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import precision_score\n\n# Create a dataframe to store the scores\nscores = pd.DataFrame(columns = ['Product','Accuracy','Precision'])\nproducts = ['ind_cco_fin_ult1', 'ind_cder_fin_ult1', 'ind_cno_fin_ult1',\n       'ind_ctju_fin_ult1', 'ind_ctma_fin_ult1', 'ind_ctop_fin_ult1',\n       'ind_ctpp_fin_ult1', 'ind_deco_fin_ult1', 'ind_deme_fin_ult1',\n       'ind_dela_fin_ult1', 'ind_ecue_fin_ult1', 'ind_fond_fin_ult1',\n       'ind_hip_fin_ult1', 'ind_plan_fin_ult1', 'ind_pres_fin_ult1',\n       'ind_reca_fin_ult1', 'ind_tjcr_fin_ult1', 'ind_valo_fin_ult1',\n       'ind_viv_fin_ult1', 'ind_nomina_ult1', 'ind_nom_pens_ult1',\n       'ind_recibo_ult1']\n\nscores[\"Product\"] = products\n\n# Calculate the metrics for all classes at once\nfor i in range(22):\n  scores[\"Precision\"][i] = precision_score(y_test.iloc[:,i],y_pred.iloc[:,i])\n\nfor i in range(22):\n  scores[\"Accuracy\"][i] = accuracy_score(y_test.iloc[:,i],y_pred.iloc[:,i])\n\n# Print the scores dataframe\nscores","metadata":{"execution":{"iopub.status.busy":"2023-05-13T20:59:32.065340Z","iopub.execute_input":"2023-05-13T20:59:32.066102Z","iopub.status.idle":"2023-05-13T20:59:56.282129Z","shell.execute_reply.started":"2023-05-13T20:59:32.066063Z","shell.execute_reply":"2023-05-13T20:59:56.281168Z"},"trusted":true},"execution_count":35,"outputs":[{"execution_count":35,"output_type":"execute_result","data":{"text/plain":"              Product  Accuracy Precision\n0    ind_cco_fin_ult1  0.603317  0.747001\n1   ind_cder_fin_ult1  0.671601  0.000766\n2    ind_cno_fin_ult1  0.518281  0.042061\n3   ind_ctju_fin_ult1  0.624303  0.006532\n4   ind_ctma_fin_ult1  0.455945  0.008379\n5   ind_ctop_fin_ult1   0.80271  0.376729\n6   ind_ctpp_fin_ult1  0.625582  0.039346\n7   ind_deco_fin_ult1   0.51643  0.002359\n8   ind_deme_fin_ult1  0.660905  0.003068\n9   ind_dela_fin_ult1  0.632736  0.057614\n10  ind_ecue_fin_ult1  0.597883  0.077177\n11  ind_fond_fin_ult1  0.681616   0.02632\n12   ind_hip_fin_ult1  0.715549  0.006707\n13  ind_plan_fin_ult1  0.713985  0.013868\n14  ind_pres_fin_ult1  0.649946  0.005246\n15  ind_reca_fin_ult1   0.64925  0.056381\n16  ind_tjcr_fin_ult1  0.655555  0.039822\n17  ind_valo_fin_ult1  0.689229  0.037708\n18   ind_viv_fin_ult1  0.714523  0.008543\n19    ind_nomina_ult1  0.457513  0.021315\n20  ind_nom_pens_ult1   0.44533  0.022784\n21    ind_recibo_ult1  0.574488  0.102226","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Product</th>\n      <th>Accuracy</th>\n      <th>Precision</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>ind_cco_fin_ult1</td>\n      <td>0.603317</td>\n      <td>0.747001</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>ind_cder_fin_ult1</td>\n      <td>0.671601</td>\n      <td>0.000766</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>ind_cno_fin_ult1</td>\n      <td>0.518281</td>\n      <td>0.042061</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>ind_ctju_fin_ult1</td>\n      <td>0.624303</td>\n      <td>0.006532</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>ind_ctma_fin_ult1</td>\n      <td>0.455945</td>\n      <td>0.008379</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>ind_ctop_fin_ult1</td>\n      <td>0.80271</td>\n      <td>0.376729</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>ind_ctpp_fin_ult1</td>\n      <td>0.625582</td>\n      <td>0.039346</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>ind_deco_fin_ult1</td>\n      <td>0.51643</td>\n      <td>0.002359</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>ind_deme_fin_ult1</td>\n      <td>0.660905</td>\n      <td>0.003068</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>ind_dela_fin_ult1</td>\n      <td>0.632736</td>\n      <td>0.057614</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>ind_ecue_fin_ult1</td>\n      <td>0.597883</td>\n      <td>0.077177</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>ind_fond_fin_ult1</td>\n      <td>0.681616</td>\n      <td>0.02632</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>ind_hip_fin_ult1</td>\n      <td>0.715549</td>\n      <td>0.006707</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>ind_plan_fin_ult1</td>\n      <td>0.713985</td>\n      <td>0.013868</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>ind_pres_fin_ult1</td>\n      <td>0.649946</td>\n      <td>0.005246</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>ind_reca_fin_ult1</td>\n      <td>0.64925</td>\n      <td>0.056381</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>ind_tjcr_fin_ult1</td>\n      <td>0.655555</td>\n      <td>0.039822</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>ind_valo_fin_ult1</td>\n      <td>0.689229</td>\n      <td>0.037708</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>ind_viv_fin_ult1</td>\n      <td>0.714523</td>\n      <td>0.008543</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>ind_nomina_ult1</td>\n      <td>0.457513</td>\n      <td>0.021315</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>ind_nom_pens_ult1</td>\n      <td>0.44533</td>\n      <td>0.022784</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>ind_recibo_ult1</td>\n      <td>0.574488</td>\n      <td>0.102226</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"El classification report es una herramienta que se utiliza para evaluar el rendimiento de un modelo de clasificación. Proporciona información sobre varias métricas que se utilizan para evaluar la precisión y la exhaustividad del modelo, así como la capacidad del modelo para identificar correctamente cada clase.\nEl reporte de clasificación incluye cuatro métricas principales: precisión, recall, f1-score y support.\n* **Precisión (precision)** es la proporción de predicciones positivas que son verdaderas positivas, es decir, la proporción de verdaderos positivos (TP) sobre la suma de verdaderos positivos y falsos positivos (FP). Indica la calidad de las predicciones positivas del modelo.\n* **Recall (también conocido como sensitividad o exhaustividad)** mide la proporción de verdaderos positivos que fueron identificados correctamente por el modelo, es decir, la proporción de verdaderos positivos sobre la suma de verdaderos positivos y falsos negativos (FN). Indica la capacidad del modelo para identificar correctamente cada clase.\n* **F1-score** es una medida ponderada de precisión y recall, que se calcula como la media armónica de ambas métricas. Es útil cuando queremos tener en cuenta ambas métricas a la hora de evaluar el rendimiento del modelo.\n* **Support** indica el número de observaciones que pertenecen a cada clase.\n\nAdemás de estas métricas, el classification report también proporciona una medida de precisión global del modelo, conocida como la media ponderada de f1-score. Esta métrica se calcula como la media ponderada del f1-score de cada clase, donde la ponderación se realiza por el número de observaciones de cada clase.","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import classification_report\n# Generar informe de clasificación\nclassification_report = classification_report(y_test, y_pred, target_names=products)\n\n# Mostrar el informe de clasificación en un formato legible\nprint(\"Informe de clasificación:\\n\\n\", classification_report)","metadata":{"execution":{"iopub.status.busy":"2023-05-13T21:00:06.171374Z","iopub.execute_input":"2023-05-13T21:00:06.172034Z","iopub.status.idle":"2023-05-13T21:00:23.563701Z","shell.execute_reply.started":"2023-05-13T21:00:06.172001Z","shell.execute_reply":"2023-05-13T21:00:23.562732Z"},"trusted":true},"execution_count":36,"outputs":[{"name":"stdout","text":"Informe de clasificación:\n\n                    precision    recall  f1-score   support\n\n ind_cco_fin_ult1       0.75      0.63      0.69   1225924\nind_cder_fin_ult1       0.00      0.74      0.00       614\n ind_cno_fin_ult1       0.04      0.49      0.08     74809\nind_ctju_fin_ult1       0.01      0.75      0.01      5911\nind_ctma_fin_ult1       0.01      0.50      0.02     16363\nind_ctop_fin_ult1       0.38      0.92      0.53    221515\nind_ctpp_fin_ult1       0.04      0.48      0.07     55066\nind_deco_fin_ult1       0.00      0.66      0.00      3102\nind_deme_fin_ult1       0.00      0.74      0.01      2518\nind_dela_fin_ult1       0.06      0.62      0.11     62738\nind_ecue_fin_ult1       0.08      0.52      0.13    107553\nind_fond_fin_ult1       0.03      0.72      0.05     21356\n ind_hip_fin_ult1       0.01      0.89      0.01      3874\nind_plan_fin_ult1       0.01      0.81      0.03      8937\nind_pres_fin_ult1       0.01      0.76      0.01      4339\nind_reca_fin_ult1       0.06      0.66      0.10     55317\nind_tjcr_fin_ult1       0.04      0.67      0.08     37461\nind_valo_fin_ult1       0.04      0.73      0.07     29361\n ind_viv_fin_ult1       0.01      0.82      0.02      5388\n  ind_nomina_ult1       0.02      0.58      0.04     35752\nind_nom_pens_ult1       0.02      0.58      0.04     39709\n  ind_recibo_ult1       0.10      0.47      0.17    164327\n\n        micro avg       0.09      0.64      0.16   2181934\n        macro avg       0.08      0.67      0.10   2181934\n     weighted avg       0.48      0.64      0.47   2181934\n      samples avg       0.12      0.55      0.19   2181934\n\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n","output_type":"stream"}]},{"cell_type":"code","source":"print(\"Overall test-accuracy across all products: \", round(scores.Accuracy.mean(), 3))\nprint(\"Overall test-precision across all products: \", round(scores.Precision.mean(), 3))","metadata":{"id":"0M4KJv490XuT","outputId":"abaa78aa-1344-436c-f041-2b533478037f","execution":{"iopub.status.busy":"2023-05-13T21:00:28.670807Z","iopub.execute_input":"2023-05-13T21:00:28.671617Z","iopub.status.idle":"2023-05-13T21:00:28.677394Z","shell.execute_reply.started":"2023-05-13T21:00:28.671574Z","shell.execute_reply":"2023-05-13T21:00:28.676596Z"},"trusted":true},"execution_count":37,"outputs":[{"name":"stdout","text":"Overall test-accuracy across all products:  0.621\nOverall test-precision across all products:  0.077\n","output_type":"stream"}]},{"cell_type":"code","source":"# Accuracy top 3 \nsorted_scores = scores.sort_values(by='Accuracy', ascending=False)\ntop_3 = sorted_scores.head(3)\nprint(top_3)\nprint(f\"Mean top 3 accuracy: {top_3['Accuracy'].mean()}\") ","metadata":{"execution":{"iopub.status.busy":"2023-05-13T21:00:31.548476Z","iopub.execute_input":"2023-05-13T21:00:31.549410Z","iopub.status.idle":"2023-05-13T21:00:31.557361Z","shell.execute_reply.started":"2023-05-13T21:00:31.549375Z","shell.execute_reply":"2023-05-13T21:00:31.556578Z"},"trusted":true},"execution_count":38,"outputs":[{"name":"stdout","text":"              Product  Accuracy Precision\n5   ind_ctop_fin_ult1   0.80271  0.376729\n12   ind_hip_fin_ult1  0.715549  0.006707\n18   ind_viv_fin_ult1  0.714523  0.008543\nMean top 3 accuracy: 0.7442605395290434\n","output_type":"stream"}]},{"cell_type":"code","source":"# Precision top 3 \nsorted_scores_p = scores.sort_values(by='Precision', ascending=False)\ntop_3 = sorted_scores_p.head(3)\nprint(top_3)\nprint(f\"Mean top 3 precision: {top_3['Precision'].mean()}\") ","metadata":{"execution":{"iopub.status.busy":"2023-05-13T21:00:43.611744Z","iopub.execute_input":"2023-05-13T21:00:43.612513Z","iopub.status.idle":"2023-05-13T21:00:43.621736Z","shell.execute_reply.started":"2023-05-13T21:00:43.612477Z","shell.execute_reply":"2023-05-13T21:00:43.620738Z"},"trusted":true},"execution_count":40,"outputs":[{"name":"stdout","text":"              Product  Accuracy Precision\n0    ind_cco_fin_ult1  0.603317  0.747001\n5   ind_ctop_fin_ult1   0.80271  0.376729\n21    ind_recibo_ult1  0.574488  0.102226\nMean top 3 precision: 0.40865225128020577\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# **6.2.1 EVALUACIÓN DE MÉTRICAS OBTENIDAS**\n\nSe ha ejecutado el modelo con los valores predeterminados para evaluar su rendimiento. Aunque el modelo muestra un accuracy general del 0.62 al predecir cada producto, su precisión es muy baja, alcanzando solo el 0.08. Sin embargo, nuestro objetivo es recomendar los productos con la mayor probabilidad de ser comprados y, por lo tanto, la métrica de evaluación será la precisión. Es importante tener en cuenta que las probabilidades de compra suelen ser muy bajas y, por lo tanto, la precisión media de los tres productos principales es baja (0.4086). Seguiremos trabajando en la hiperafinación de los parámetros para encontrar un modelo más preciso y adecuado a nuestro objetivo.","metadata":{"id":"wzKpv4le0XuU"}},{"cell_type":"markdown","source":"# **6.2.2. Ajuste de hiperparámetros para mejorar el modelo**\n\nPara mejorar el rendimiento de nuestro modelo, hemos utilizado la técnica de ajuste de hiperparámetros GridSearchCV. Esta técnica nos permite buscar la combinación óptima de valores de hiperparámetros para nuestro modelo.\n\nGridSearchCV realiza una búsqueda exhaustiva de los valores óptimos para los hiperparámetros especificados. Para ello, se proporciona una cuadrícula de valores de parámetros y se realiza una búsqueda de todas las posibles combinaciones de valores en la cuadrícula. El algoritmo devuelve entonces el conjunto de valores de parámetros que produce el mejor rendimiento según una métrica de evaluación.\n\nLa variable best_params_ de GridSearchCV nos proporciona la combinación de hiperparámetros que resulta en el mejor rendimiento de acuerdo con nuestra puntuación con los datos de prueba, ya que evalúa cada combinación posible. De esta manera, podemos estar seguros de que estamos utilizando la configuración óptima de hiperparámetros para nuestro modelo y, por lo tanto, maximizando su rendimiento.","metadata":{"id":"W8sNBIiG0XuW"}},{"cell_type":"code","source":"#Este código utiliza GridSearchCV para ajustar los parámetros de un modelo MultinomialNB y encontrar el mejor valor de alpha para mejorar la precisión ponderada del modelo. \n#También utiliza validación cruzada con 10 pliegues (cv=10) para reducir el posible sobreajuste. \n#La puntuación utilizada para evaluar el modelo es precision_weighted, que es una medida que tiene en cuenta el desequilibrio en la distribución de clases en los datos. \n#Finalmente, el código imprime los mejores parámetros encontrados y la mejor puntuación obtenida.\n\n# Importar la clase GridSearchCV de scikit-learn\nfrom sklearn.model_selection import GridSearchCV\n\n# Definir una lista de parámetros para ajustar el modelo\nparameters = [\n    {\n        'classifier': [MultinomialNB()],\n        'classifier__alpha': [0.3, 0.5, 0.7, 1.0], # Ajustar el suavizado del modelo\n    }\n]\n\n# Crear un objeto GridSearchCV y ajustar el modelo con los parámetros definidos\nclassifier_gridsearch = GridSearchCV(BinaryRelevance(), parameters, scoring='precision_weighted', cv=10)\nclassifier_gridsearch.fit(X_train, y_train)\n\n# Imprimir los mejores parámetros y la mejor puntuación obtenida\nprint(\"Los mejores parámetros encontrados son:\", classifier_gridsearch.best_params_)\nprint(\"La mejor puntuación obtenida es:\", classifier_gridsearch.best_score_)\n\n# Obtener el mejor valor de alpha encontrado\nbest_a = classifier_gridsearch.best_params_[\"classifier__alpha\"]","metadata":{"execution":{"iopub.status.busy":"2023-05-13T21:01:11.572054Z","iopub.execute_input":"2023-05-13T21:01:11.572428Z","iopub.status.idle":"2023-05-13T21:54:12.106924Z","shell.execute_reply.started":"2023-05-13T21:01:11.572398Z","shell.execute_reply":"2023-05-13T21:54:12.106033Z"},"trusted":true},"execution_count":42,"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Los mejores parámetros encontrados son: {'classifier': MultinomialNB(alpha=0.3), 'classifier__alpha': 0.3}\nLa mejor puntuación obtenida es: 0.4773484056603734\n","output_type":"stream"}]},{"cell_type":"code","source":"best_a","metadata":{"execution":{"iopub.status.busy":"2023-05-13T21:54:18.796219Z","iopub.execute_input":"2023-05-13T21:54:18.796920Z","iopub.status.idle":"2023-05-13T21:54:18.802048Z","shell.execute_reply.started":"2023-05-13T21:54:18.796885Z","shell.execute_reply":"2023-05-13T21:54:18.801290Z"},"trusted":true},"execution_count":43,"outputs":[{"execution_count":43,"output_type":"execute_result","data":{"text/plain":"0.3"},"metadata":{}}]},{"cell_type":"markdown","source":"**Se vuelve a entrenar el modelo con los mejores hiperpatametros encontrados**","metadata":{}},{"cell_type":"code","source":"# Create a Binary Relevance classifier using MultinomialNB algorithm for multi-class classification\nbin_rel_classifier = BinaryRelevance(MultinomialNB(alpha=best_a))\n\n# The classifier cannot handle negative values, so we need to modify the instances of the _change function\n# Where a product has been dropped from the value -1 to 0, limiting us from three dimensions (dropped, unchanged, added)\n# to two dimensions (unchanged or dropped, added)\n\n# Fit the model\nbin_rel_classifier.fit(X_train, y_train)\n\n# Make predictions on the test set\ny_pred = bin_rel_classifier.predict(X_test)\n\n# Convert the sparse matrix to a dense array and create a Pandas dataframe from it\ny_pred = pd.DataFrame(y_pred.toarray())","metadata":{"execution":{"iopub.status.busy":"2023-05-13T21:57:24.127213Z","iopub.execute_input":"2023-05-13T21:57:24.128059Z","iopub.status.idle":"2023-05-13T21:58:47.030173Z","shell.execute_reply.started":"2023-05-13T21:57:24.128027Z","shell.execute_reply":"2023-05-13T21:58:47.029060Z"},"trusted":true},"execution_count":51,"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n/usr/local/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"#evaluate the model with accuracy and precision score for the test set\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import precision_score\n\n# Create a dataframe to store the scores\nscores = pd.DataFrame(columns = ['Product','Accuracy','Precision'])\nproducts = ['ind_cco_fin_ult1', 'ind_cder_fin_ult1', 'ind_cno_fin_ult1',\n       'ind_ctju_fin_ult1', 'ind_ctma_fin_ult1', 'ind_ctop_fin_ult1',\n       'ind_ctpp_fin_ult1', 'ind_deco_fin_ult1', 'ind_deme_fin_ult1',\n       'ind_dela_fin_ult1', 'ind_ecue_fin_ult1', 'ind_fond_fin_ult1',\n       'ind_hip_fin_ult1', 'ind_plan_fin_ult1', 'ind_pres_fin_ult1',\n       'ind_reca_fin_ult1', 'ind_tjcr_fin_ult1', 'ind_valo_fin_ult1',\n       'ind_viv_fin_ult1', 'ind_nomina_ult1', 'ind_nom_pens_ult1',\n       'ind_recibo_ult1']\n\nscores[\"Product\"] = products\n\n# Calculate the metrics for all classes at once\nfor i in range(22):\n  scores[\"Precision\"][i] = precision_score(y_test.iloc[:,i],y_pred.iloc[:,i])\n\nfor i in range(22):\n  scores[\"Accuracy\"][i] = accuracy_score(y_test.iloc[:,i],y_pred.iloc[:,i])\n\n# Print the scores dataframe\nscores","metadata":{"execution":{"iopub.status.busy":"2023-05-13T21:58:51.967101Z","iopub.execute_input":"2023-05-13T21:58:51.967803Z","iopub.status.idle":"2023-05-13T21:59:16.443492Z","shell.execute_reply.started":"2023-05-13T21:58:51.967772Z","shell.execute_reply":"2023-05-13T21:59:16.442420Z"},"trusted":true},"execution_count":52,"outputs":[{"execution_count":52,"output_type":"execute_result","data":{"text/plain":"              Product  Accuracy Precision\n0    ind_cco_fin_ult1  0.603317  0.747001\n1   ind_cder_fin_ult1  0.671601  0.000766\n2    ind_cno_fin_ult1  0.518281  0.042061\n3   ind_ctju_fin_ult1  0.624303  0.006532\n4   ind_ctma_fin_ult1  0.455945  0.008379\n5   ind_ctop_fin_ult1   0.80271  0.376729\n6   ind_ctpp_fin_ult1  0.625582  0.039346\n7   ind_deco_fin_ult1   0.51643  0.002359\n8   ind_deme_fin_ult1  0.660905  0.003068\n9   ind_dela_fin_ult1  0.632736  0.057614\n10  ind_ecue_fin_ult1  0.597883  0.077177\n11  ind_fond_fin_ult1  0.681616   0.02632\n12   ind_hip_fin_ult1  0.715549  0.006707\n13  ind_plan_fin_ult1  0.713985  0.013868\n14  ind_pres_fin_ult1  0.649946  0.005246\n15  ind_reca_fin_ult1   0.64925  0.056381\n16  ind_tjcr_fin_ult1  0.655555  0.039822\n17  ind_valo_fin_ult1  0.689229  0.037708\n18   ind_viv_fin_ult1  0.714523  0.008543\n19    ind_nomina_ult1  0.457513  0.021315\n20  ind_nom_pens_ult1   0.44533  0.022784\n21    ind_recibo_ult1  0.574488  0.102226","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Product</th>\n      <th>Accuracy</th>\n      <th>Precision</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>ind_cco_fin_ult1</td>\n      <td>0.603317</td>\n      <td>0.747001</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>ind_cder_fin_ult1</td>\n      <td>0.671601</td>\n      <td>0.000766</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>ind_cno_fin_ult1</td>\n      <td>0.518281</td>\n      <td>0.042061</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>ind_ctju_fin_ult1</td>\n      <td>0.624303</td>\n      <td>0.006532</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>ind_ctma_fin_ult1</td>\n      <td>0.455945</td>\n      <td>0.008379</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>ind_ctop_fin_ult1</td>\n      <td>0.80271</td>\n      <td>0.376729</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>ind_ctpp_fin_ult1</td>\n      <td>0.625582</td>\n      <td>0.039346</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>ind_deco_fin_ult1</td>\n      <td>0.51643</td>\n      <td>0.002359</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>ind_deme_fin_ult1</td>\n      <td>0.660905</td>\n      <td>0.003068</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>ind_dela_fin_ult1</td>\n      <td>0.632736</td>\n      <td>0.057614</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>ind_ecue_fin_ult1</td>\n      <td>0.597883</td>\n      <td>0.077177</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>ind_fond_fin_ult1</td>\n      <td>0.681616</td>\n      <td>0.02632</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>ind_hip_fin_ult1</td>\n      <td>0.715549</td>\n      <td>0.006707</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>ind_plan_fin_ult1</td>\n      <td>0.713985</td>\n      <td>0.013868</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>ind_pres_fin_ult1</td>\n      <td>0.649946</td>\n      <td>0.005246</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>ind_reca_fin_ult1</td>\n      <td>0.64925</td>\n      <td>0.056381</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>ind_tjcr_fin_ult1</td>\n      <td>0.655555</td>\n      <td>0.039822</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>ind_valo_fin_ult1</td>\n      <td>0.689229</td>\n      <td>0.037708</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>ind_viv_fin_ult1</td>\n      <td>0.714523</td>\n      <td>0.008543</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>ind_nomina_ult1</td>\n      <td>0.457513</td>\n      <td>0.021315</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>ind_nom_pens_ult1</td>\n      <td>0.44533</td>\n      <td>0.022784</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>ind_recibo_ult1</td>\n      <td>0.574488</td>\n      <td>0.102226</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"from sklearn.metrics import classification_report\n# Generar informe de clasificación\nclassification_report = classification_report(y_test, y_pred, target_names=products)\n\n# Mostrar el informe de clasificación en un formato legible\nprint(\"Informe de clasificación:\\n\\n\", classification_report)","metadata":{"execution":{"iopub.status.busy":"2023-05-13T21:59:19.777188Z","iopub.execute_input":"2023-05-13T21:59:19.778567Z","iopub.status.idle":"2023-05-13T21:59:37.306264Z","shell.execute_reply.started":"2023-05-13T21:59:19.778525Z","shell.execute_reply":"2023-05-13T21:59:37.305186Z"},"trusted":true},"execution_count":53,"outputs":[{"name":"stdout","text":"Informe de clasificación:\n\n                    precision    recall  f1-score   support\n\n ind_cco_fin_ult1       0.75      0.63      0.69   1225924\nind_cder_fin_ult1       0.00      0.74      0.00       614\n ind_cno_fin_ult1       0.04      0.49      0.08     74809\nind_ctju_fin_ult1       0.01      0.75      0.01      5911\nind_ctma_fin_ult1       0.01      0.50      0.02     16363\nind_ctop_fin_ult1       0.38      0.92      0.53    221515\nind_ctpp_fin_ult1       0.04      0.48      0.07     55066\nind_deco_fin_ult1       0.00      0.66      0.00      3102\nind_deme_fin_ult1       0.00      0.74      0.01      2518\nind_dela_fin_ult1       0.06      0.62      0.11     62738\nind_ecue_fin_ult1       0.08      0.52      0.13    107553\nind_fond_fin_ult1       0.03      0.72      0.05     21356\n ind_hip_fin_ult1       0.01      0.89      0.01      3874\nind_plan_fin_ult1       0.01      0.81      0.03      8937\nind_pres_fin_ult1       0.01      0.76      0.01      4339\nind_reca_fin_ult1       0.06      0.66      0.10     55317\nind_tjcr_fin_ult1       0.04      0.67      0.08     37461\nind_valo_fin_ult1       0.04      0.73      0.07     29361\n ind_viv_fin_ult1       0.01      0.82      0.02      5388\n  ind_nomina_ult1       0.02      0.58      0.04     35752\nind_nom_pens_ult1       0.02      0.58      0.04     39709\n  ind_recibo_ult1       0.10      0.47      0.17    164327\n\n        micro avg       0.09      0.64      0.16   2181934\n        macro avg       0.08      0.67      0.10   2181934\n     weighted avg       0.48      0.64      0.47   2181934\n      samples avg       0.12      0.55      0.19   2181934\n\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n","output_type":"stream"}]},{"cell_type":"code","source":"print(\"Overall test-accuracy across all products: \", scores.Accuracy.mean().round(3))\nprint(\"Overall test-precision across all products: \", scores.Precision.mean().round(3))","metadata":{"id":"MKeOfEB-0XuY","outputId":"1888b38b-656d-4c53-a3f7-35c1b2ce447e","execution":{"iopub.status.busy":"2023-05-13T21:59:41.129048Z","iopub.execute_input":"2023-05-13T21:59:41.129466Z","iopub.status.idle":"2023-05-13T21:59:41.136601Z","shell.execute_reply.started":"2023-05-13T21:59:41.129435Z","shell.execute_reply":"2023-05-13T21:59:41.135705Z"},"trusted":true},"execution_count":54,"outputs":[{"name":"stdout","text":"Overall test-accuracy across all products:  0.621\nOverall test-precision across all products:  0.077\n","output_type":"stream"}]},{"cell_type":"code","source":"# Accuracy top 3 \nsorted_scores = scores.sort_values(by='Accuracy', ascending=False)\ntop_3 = sorted_scores.head(3)\nprint(top_3)\nprint(f\"Mean top 3 accuracy: {top_3['Accuracy'].mean()}\") ","metadata":{"execution":{"iopub.status.busy":"2023-05-13T21:59:44.231394Z","iopub.execute_input":"2023-05-13T21:59:44.232296Z","iopub.status.idle":"2023-05-13T21:59:44.241811Z","shell.execute_reply.started":"2023-05-13T21:59:44.232258Z","shell.execute_reply":"2023-05-13T21:59:44.240867Z"},"trusted":true},"execution_count":55,"outputs":[{"name":"stdout","text":"              Product  Accuracy Precision\n5   ind_ctop_fin_ult1   0.80271  0.376729\n12   ind_hip_fin_ult1  0.715549  0.006707\n18   ind_viv_fin_ult1  0.714523  0.008543\nMean top 3 accuracy: 0.7442605395290434\n","output_type":"stream"}]},{"cell_type":"code","source":"# Precision top 3 \nsorted_scores_p = scores.sort_values(by='Precision', ascending=False)\ntop_3 = sorted_scores_p.head(3)\nprint(top_3)\nprint(f\"Mean top 3 precision: {top_3['Precision'].mean()}\") ","metadata":{"execution":{"iopub.status.busy":"2023-05-13T21:59:47.060179Z","iopub.execute_input":"2023-05-13T21:59:47.061063Z","iopub.status.idle":"2023-05-13T21:59:47.070408Z","shell.execute_reply.started":"2023-05-13T21:59:47.061025Z","shell.execute_reply":"2023-05-13T21:59:47.069473Z"},"trusted":true},"execution_count":56,"outputs":[{"name":"stdout","text":"              Product  Accuracy Precision\n0    ind_cco_fin_ult1  0.603317  0.747001\n5   ind_ctop_fin_ult1   0.80271  0.376729\n21    ind_recibo_ult1  0.574488  0.102226\nMean top 3 precision: 0.40865225128020577\n","output_type":"stream"}]},{"cell_type":"code","source":"MatrizDecision = pd.DataFrame({'Overall test_accuracy': [0.621, 0.621],\n                   'Overall test_precision': [0.077, 0.077],\n                   'Mean top 3 accuracy': [0.7442, 0.7443],\n                   'Mean top 3 precision': [0.4086, 0.4087]\n                   })\nMatrizDecision.index = ['Naive Bayes con parámetros predeterminados', 'Naive Bayes con hiperparámetros']\n\nprint(MatrizDecision)","metadata":{"execution":{"iopub.status.busy":"2023-05-13T22:02:26.309209Z","iopub.execute_input":"2023-05-13T22:02:26.309690Z","iopub.status.idle":"2023-05-13T22:02:26.321178Z","shell.execute_reply.started":"2023-05-13T22:02:26.309654Z","shell.execute_reply":"2023-05-13T22:02:26.320126Z"},"trusted":true},"execution_count":58,"outputs":[{"name":"stdout","text":"                                            Overall test_accuracy   \nNaive Bayes con parámetros predeterminados                  0.621  \\\nNaive Bayes con hiperparámetros                             0.621   \n\n                                            Overall test_precision   \nNaive Bayes con parámetros predeterminados                   0.077  \\\nNaive Bayes con hiperparámetros                              0.077   \n\n                                            Mean top 3 accuracy   \nNaive Bayes con parámetros predeterminados               0.7442  \\\nNaive Bayes con hiperparámetros                          0.7443   \n\n                                            Mean top 3 precision  \nNaive Bayes con parámetros predeterminados                0.4086  \nNaive Bayes con hiperparámetros                           0.4087  \n","output_type":"stream"}]},{"cell_type":"markdown","source":"**ANÁLISIS MODELO OPTIMIZADO**\n\n**Después de optimizar nuestro modelo con el objetivo de aumentar su precisión, hemos observado una mejora mínima en el rendimiento general del modelo. A pesar de identificar los 3 productos con la mayor precisión, estos valores siguen siendo muy bajos, con un promedio de solo 0,409. Dado que los resultados no son satisfactorios, concluimos que este modelo no es adecuado para nuestras necesidades y exploraremos otros algoritmos estudiados para encontrar uno más efectivo.**","metadata":{"id":"PFmEWwO-0XuZ"}},{"cell_type":"markdown","source":"**Después de encontrar que el rendimiento del modelo Naive Bayes no cumplía con nuestros requisitos de precisión, hemos decidido probar con otro algoritmo que nos pueda ofrecer mejores resultados. Para ello, hemos optado por probar XGBoost, que es una implementación de árboles de decisión potenciados por gradiente diseñados especialmente para velocidad y rendimiento, lo que parece ser apropiado para nuestro problema.**\n","metadata":{"id":"GHI_ZFqZ0XuZ"}},{"cell_type":"markdown","source":"> # **6.3 XGBOOST**\n![](https://cdn.educba.com/academy/wp-content/uploads/2019/06/XGBoost-Algorithm-2.jpg)","metadata":{"id":"qPS9eSyV0Xua"}},{"cell_type":"code","source":"clientes_modelado=pd.read_csv('clientes_modelado.csv', header=0)\nclientes_modelado.head()","metadata":{"id":"grmkjre60Xua","outputId":"2e4effca-6a91-4a5f-90ed-0ca94de3b877","execution":{"iopub.status.busy":"2023-05-13T22:50:12.251613Z","iopub.execute_input":"2023-05-13T22:50:12.252564Z","iopub.status.idle":"2023-05-13T22:50:52.904127Z","shell.execute_reply.started":"2023-05-13T22:50:12.252523Z","shell.execute_reply":"2023-05-13T22:50:52.903061Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"   fecha_dato  ncodpers  ind_empleado  sexo   age  fecha_alta  ind_nuevo   \n0  20150128.0   1375586           3.0   0.0  35.0  20150112.0        0.0  \\\n1  20150228.0   1375586           3.0   0.0  35.0  20150112.0        0.0   \n2  20150328.0   1375586           3.0   0.0  35.0  20150112.0        0.0   \n3  20150428.0   1375586           3.0   0.0  35.0  20150112.0        0.0   \n4  20150528.0   1375586           3.0   0.0  35.0  20150112.0        0.0   \n\n   indrel  indrel_1mes  tiprel_1mes  ...  ind_hip_fin_ult1  ind_plan_fin_ult1   \n0     1.0            1          0.0  ...                 0                  0  \\\n1     1.0            1          0.0  ...                 0                  0   \n2     1.0            1          0.0  ...                 0                  0   \n3     1.0            1          0.0  ...                 0                  0   \n4     1.0            1          0.0  ...                 0                  0   \n\n   ind_pres_fin_ult1  ind_reca_fin_ult1  ind_tjcr_fin_ult1  ind_valo_fin_ult1   \n0                  0                  0                  0                  0  \\\n1                  0                  0                  0                  0   \n2                  0                  0                  0                  0   \n3                  0                  0                  0                  0   \n4                  0                  0                  0                  0   \n\n   ind_viv_fin_ult1  ind_nomina_ult1  ind_nom_pens_ult1  ind_recibo_ult1  \n0                 0              0.0                0.0                0  \n1                 0              0.0                0.0                0  \n2                 0              0.0                0.0                0  \n3                 0              0.0                0.0                0  \n4                 0              0.0                0.0                1  \n\n[5 rows x 39 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>fecha_dato</th>\n      <th>ncodpers</th>\n      <th>ind_empleado</th>\n      <th>sexo</th>\n      <th>age</th>\n      <th>fecha_alta</th>\n      <th>ind_nuevo</th>\n      <th>indrel</th>\n      <th>indrel_1mes</th>\n      <th>tiprel_1mes</th>\n      <th>...</th>\n      <th>ind_hip_fin_ult1</th>\n      <th>ind_plan_fin_ult1</th>\n      <th>ind_pres_fin_ult1</th>\n      <th>ind_reca_fin_ult1</th>\n      <th>ind_tjcr_fin_ult1</th>\n      <th>ind_valo_fin_ult1</th>\n      <th>ind_viv_fin_ult1</th>\n      <th>ind_nomina_ult1</th>\n      <th>ind_nom_pens_ult1</th>\n      <th>ind_recibo_ult1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>20150128.0</td>\n      <td>1375586</td>\n      <td>3.0</td>\n      <td>0.0</td>\n      <td>35.0</td>\n      <td>20150112.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>20150228.0</td>\n      <td>1375586</td>\n      <td>3.0</td>\n      <td>0.0</td>\n      <td>35.0</td>\n      <td>20150112.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>20150328.0</td>\n      <td>1375586</td>\n      <td>3.0</td>\n      <td>0.0</td>\n      <td>35.0</td>\n      <td>20150112.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>20150428.0</td>\n      <td>1375586</td>\n      <td>3.0</td>\n      <td>0.0</td>\n      <td>35.0</td>\n      <td>20150112.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>20150528.0</td>\n      <td>1375586</td>\n      <td>3.0</td>\n      <td>0.0</td>\n      <td>35.0</td>\n      <td>20150112.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 39 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"clientes_modelado.drop(columns=['fecha_dato'],inplace = True)","metadata":{"id":"EGVCZEXH0Xua","execution":{"iopub.status.busy":"2023-05-13T22:51:39.107171Z","iopub.execute_input":"2023-05-13T22:51:39.108547Z","iopub.status.idle":"2023-05-13T22:51:40.332866Z","shell.execute_reply.started":"2023-05-13T22:51:39.108497Z","shell.execute_reply":"2023-05-13T22:51:40.331693Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"#se selecciona el 70% de las filas del dataset original, es decir, se está realizando una reducción del tamaño del dataset original \n#para poder trabajar con una muestra más pequeña y eficiente.\nclientes_modelado=clientes_modelado.sample(frac=0.7)","metadata":{"id":"881xKFzp0Xub","execution":{"iopub.status.busy":"2023-05-13T22:51:42.794141Z","iopub.execute_input":"2023-05-13T22:51:42.795336Z","iopub.status.idle":"2023-05-13T22:51:48.836985Z","shell.execute_reply.started":"2023-05-13T22:51:42.795286Z","shell.execute_reply":"2023-05-13T22:51:48.835717Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"**TRAIN-TEST SPLIT**","metadata":{"id":"G4gCFidT0Xub"}},{"cell_type":"code","source":"#Separate independent and dependent variables\nX = clientes_modelado.iloc[:,0:16] #variables independientes\nY = clientes_modelado.iloc[:,16:38]    #target variable\n\nfrom sklearn.model_selection import train_test_split\n\n#Split the data into train and test sets\nX_train, X_test, y_train, y_test = train_test_split(X, Y,test_size=0.2,random_state=42)","metadata":{"id":"Hewi8zm40Xub","execution":{"iopub.status.busy":"2023-05-13T22:51:51.117126Z","iopub.execute_input":"2023-05-13T22:51:51.118279Z","iopub.status.idle":"2023-05-13T22:51:58.336896Z","shell.execute_reply.started":"2023-05-13T22:51:51.118234Z","shell.execute_reply":"2023-05-13T22:51:58.335703Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"**XGBoost es una implementación de árboles de decisión potenciados por gradiente que se ha vuelto popular en competiciones de aprendizaje automático debido a su velocidad y rendimiento. Se utiliza para problemas de clasificación y regresión, y funciona bien en conjuntos de datos grandes y complejos.\nEn nuestro caso, como estamos tratando de clasificar múltiples etiquetas, utilizamos la clase MultioutputClassifier de Scikit-learn, que permite ajustar un clasificador diferente para cada etiqueta. Esto significa que en lugar de tener un solo clasificador que clasifica todas las etiquetas juntas, tenemos varios clasificadores, uno para cada etiqueta. Esto puede ser especialmente útil para ampliar los clasificadores que no admiten de forma nativa la clasificación de objetivos múltiples.\nEn resumen, al aplicar XGBoost con MultioutputClassifier en nuestro conjunto de datos, esperamos obtener mejores resultados en términos de precisión y rendimiento que con nuestro modelo anterior.**","metadata":{"id":"8cGz2guT0Xuc"}},{"cell_type":"code","source":"# Ajuste del modelo XGBoost con MultiOutputClassifier y parámetros predeterminados\nfrom xgboost import XGBClassifier\nfrom sklearn.multioutput import MultiOutputClassifier\n\nxgboost_classifier = MultiOutputClassifier(estimator=XGBClassifier())\n\nprint(\"Ajustando el modelo XGBoost...\")\nxgboost_classifier.fit(X_train, y_train)\nprint(\"El modelo ha sido ajustado exitosamente.\")","metadata":{"id":"brLYgJpd0Xuc","outputId":"c92dd01a-d86f-4f2e-a6b5-1ebb6c985ed9","execution":{"iopub.status.busy":"2023-05-13T22:52:02.002425Z","iopub.execute_input":"2023-05-13T22:52:02.003335Z","iopub.status.idle":"2023-05-13T23:22:47.735621Z","shell.execute_reply.started":"2023-05-13T22:52:02.003298Z","shell.execute_reply":"2023-05-13T23:22:47.734761Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"Ajustando el modelo XGBoost...\nEl modelo ha sido ajustado exitosamente.\n","output_type":"stream"}]},{"cell_type":"code","source":"# Realizar predicciones sobre los datos de entrenamiento\ny_train_pred_xgb = xgboost_classifier.predict(X_train)\n\n# Convertir las predicciones a un DataFrame de pandas\ny_train_pred_xgb = pd.DataFrame(y_train_pred_xgb, columns=y_train.columns)\n\n# Comprobar que las dimensiones son correctas\nprint(\"Dimensiones de y_train_pred_xgb:\", y_train_pred_xgb.shape)","metadata":{"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"Dimensiones de y_train_pred_xgb: (7186560, 22)\n","output_type":"stream"}]},{"cell_type":"code","source":"y_train_pred_xgb","metadata":{"execution":{"iopub.status.busy":"2023-05-13T23:23:20.607605Z","iopub.execute_input":"2023-05-13T23:23:20.607984Z","iopub.status.idle":"2023-05-13T23:23:21.477715Z","shell.execute_reply.started":"2023-05-13T23:23:20.607954Z","shell.execute_reply":"2023-05-13T23:23:21.476920Z"},"trusted":true},"execution_count":13,"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"         ind_cco_fin_ult1  ind_cder_fin_ult1  ind_cno_fin_ult1   \n0                       0                  0                 0  \\\n1                       1                  0                 0   \n2                       1                  0                 0   \n3                       1                  0                 0   \n4                       0                  0                 0   \n...                   ...                ...               ...   \n7186555                 1                  0                 0   \n7186556                 1                  0                 0   \n7186557                 0                  0                 0   \n7186558                 1                  0                 0   \n7186559                 0                  0                 0   \n\n         ind_ctju_fin_ult1  ind_ctma_fin_ult1  ind_ctop_fin_ult1   \n0                        0                  0                  0  \\\n1                        0                  0                  0   \n2                        0                  0                  0   \n3                        0                  0                  0   \n4                        0                  0                  0   \n...                    ...                ...                ...   \n7186555                  0                  0                  0   \n7186556                  0                  0                  0   \n7186557                  0                  0                  0   \n7186558                  0                  0                  0   \n7186559                  0                  0                  0   \n\n         ind_ctpp_fin_ult1  ind_deco_fin_ult1  ind_deme_fin_ult1   \n0                        0                  0                  0  \\\n1                        0                  0                  0   \n2                        0                  0                  0   \n3                        0                  0                  0   \n4                        0                  0                  0   \n...                    ...                ...                ...   \n7186555                  0                  0                  0   \n7186556                  0                  0                  0   \n7186557                  0                  0                  0   \n7186558                  0                  0                  0   \n7186559                  0                  0                  0   \n\n         ind_dela_fin_ult1  ...  ind_hip_fin_ult1  ind_plan_fin_ult1   \n0                        0  ...                 0                  0  \\\n1                        0  ...                 0                  0   \n2                        0  ...                 0                  0   \n3                        0  ...                 0                  0   \n4                        0  ...                 0                  0   \n...                    ...  ...               ...                ...   \n7186555                  0  ...                 0                  0   \n7186556                  0  ...                 0                  0   \n7186557                  0  ...                 0                  0   \n7186558                  0  ...                 0                  0   \n7186559                  0  ...                 0                  0   \n\n         ind_pres_fin_ult1  ind_reca_fin_ult1  ind_tjcr_fin_ult1   \n0                        0                  0                  0  \\\n1                        0                  0                  0   \n2                        0                  0                  0   \n3                        0                  0                  0   \n4                        0                  0                  0   \n...                    ...                ...                ...   \n7186555                  0                  0                  0   \n7186556                  0                  0                  0   \n7186557                  0                  0                  0   \n7186558                  0                  0                  0   \n7186559                  0                  0                  0   \n\n         ind_valo_fin_ult1  ind_viv_fin_ult1  ind_nomina_ult1   \n0                        0                 0                0  \\\n1                        0                 0                0   \n2                        0                 0                0   \n3                        0                 0                0   \n4                        0                 0                0   \n...                    ...               ...              ...   \n7186555                  0                 0                0   \n7186556                  0                 0                0   \n7186557                  0                 0                0   \n7186558                  0                 0                0   \n7186559                  0                 0                0   \n\n         ind_nom_pens_ult1  ind_recibo_ult1  \n0                        0                0  \n1                        0                0  \n2                        0                0  \n3                        0                0  \n4                        0                0  \n...                    ...              ...  \n7186555                  0                0  \n7186556                  0                0  \n7186557                  0                0  \n7186558                  0                0  \n7186559                  0                0  \n\n[7186560 rows x 22 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ind_cco_fin_ult1</th>\n      <th>ind_cder_fin_ult1</th>\n      <th>ind_cno_fin_ult1</th>\n      <th>ind_ctju_fin_ult1</th>\n      <th>ind_ctma_fin_ult1</th>\n      <th>ind_ctop_fin_ult1</th>\n      <th>ind_ctpp_fin_ult1</th>\n      <th>ind_deco_fin_ult1</th>\n      <th>ind_deme_fin_ult1</th>\n      <th>ind_dela_fin_ult1</th>\n      <th>...</th>\n      <th>ind_hip_fin_ult1</th>\n      <th>ind_plan_fin_ult1</th>\n      <th>ind_pres_fin_ult1</th>\n      <th>ind_reca_fin_ult1</th>\n      <th>ind_tjcr_fin_ult1</th>\n      <th>ind_valo_fin_ult1</th>\n      <th>ind_viv_fin_ult1</th>\n      <th>ind_nomina_ult1</th>\n      <th>ind_nom_pens_ult1</th>\n      <th>ind_recibo_ult1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>7186555</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>7186556</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>7186557</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>7186558</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>7186559</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>7186560 rows × 22 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"y_pred = pd.DataFrame(xgboost_classifier.predict(X_test))","metadata":{"execution":{"iopub.status.busy":"2023-05-13T23:23:24.729903Z","iopub.execute_input":"2023-05-13T23:23:24.730844Z","iopub.status.idle":"2023-05-13T23:23:29.637596Z","shell.execute_reply.started":"2023-05-13T23:23:24.730806Z","shell.execute_reply":"2023-05-13T23:23:29.636753Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"y_pred","metadata":{"execution":{"iopub.status.busy":"2023-05-13T23:23:34.098362Z","iopub.execute_input":"2023-05-13T23:23:34.099272Z","iopub.status.idle":"2023-05-13T23:23:34.235190Z","shell.execute_reply.started":"2023-05-13T23:23:34.099237Z","shell.execute_reply":"2023-05-13T23:23:34.234362Z"},"trusted":true},"execution_count":15,"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"         0   1   2   3   4   5   6   7   8   9   ...  12  13  14  15  16  17   \n0         0   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   0  \\\n1         1   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   \n2         1   0   0   0   0   0   0   0   0   1  ...   0   0   0   0   0   0   \n3         1   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   \n4         1   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   \n...      ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ...  ..  ..  ..  ..  ..  ..   \n1796636   0   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   \n1796637   1   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   \n1796638   1   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   \n1796639   1   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   \n1796640   1   0   0   0   0   1   0   0   0   0  ...   0   0   0   0   0   0   \n\n         18  19  20  21  \n0         0   0   0   0  \n1         0   0   0   0  \n2         0   0   0   0  \n3         0   0   0   0  \n4         0   0   0   0  \n...      ..  ..  ..  ..  \n1796636   0   0   0   0  \n1796637   0   0   0   0  \n1796638   0   0   0   0  \n1796639   0   0   0   0  \n1796640   0   0   0   0  \n\n[1796641 rows x 22 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>...</th>\n      <th>12</th>\n      <th>13</th>\n      <th>14</th>\n      <th>15</th>\n      <th>16</th>\n      <th>17</th>\n      <th>18</th>\n      <th>19</th>\n      <th>20</th>\n      <th>21</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1796636</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1796637</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1796638</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1796639</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1796640</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>1796641 rows × 22 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n\n# Create a dataframe to store the scores\nscores = pd.DataFrame(columns = ['Product','Accuracy','Precision'])\nproducts = ['ind_cco_fin_ult1', 'ind_cder_fin_ult1', 'ind_cno_fin_ult1',\n       'ind_ctju_fin_ult1', 'ind_ctma_fin_ult1', 'ind_ctop_fin_ult1',\n       'ind_ctpp_fin_ult1', 'ind_deco_fin_ult1', 'ind_deme_fin_ult1',\n       'ind_dela_fin_ult1', 'ind_ecue_fin_ult1', 'ind_fond_fin_ult1',\n       'ind_hip_fin_ult1', 'ind_plan_fin_ult1', 'ind_pres_fin_ult1',\n       'ind_reca_fin_ult1', 'ind_tjcr_fin_ult1', 'ind_valo_fin_ult1',\n       'ind_viv_fin_ult1', 'ind_nomina_ult1', 'ind_nom_pens_ult1',\n       'ind_recibo_ult1']\nscores[\"Product\"] = products\n\n# Calculate the metrics for all classes at once\nfor i in range(22):\n  scores[\"Precision\"][i] = precision_score(y_train.iloc[:,i],y_train_pred_xgb.iloc[:,i])\n\nfor i in range(22):\n  scores[\"Accuracy\"][i] = accuracy_score(y_train.iloc[:,i],y_train_pred_xgb.iloc[:,i])\n\n# Print the scores dataframe\nscores","metadata":{"id":"jY10eg4i0Xud","outputId":"440daca3-a2d1-43dc-9bd9-0c5dc8b15309","trusted":true},"execution_count":16,"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"              Product  Accuracy Precision\n0    ind_cco_fin_ult1  0.773949   0.80987\n1   ind_cder_fin_ult1  0.999751  0.992565\n2    ind_cno_fin_ult1  0.954084  0.817844\n3   ind_ctju_fin_ult1  0.999836  0.981554\n4   ind_ctma_fin_ult1  0.992642  0.729721\n5   ind_ctop_fin_ult1  0.901637  0.640403\n6   ind_ctpp_fin_ult1   0.97212  0.647338\n7   ind_deco_fin_ult1  0.998346  0.692992\n8   ind_deme_fin_ult1   0.99882  0.988636\n9   ind_dela_fin_ult1  0.972227  0.655142\n10  ind_ecue_fin_ult1  0.946193  0.659859\n11  ind_fond_fin_ult1  0.990089  0.930912\n12   ind_hip_fin_ult1  0.997989  0.934673\n13  ind_plan_fin_ult1  0.995895  0.951351\n14  ind_pres_fin_ult1  0.998661  0.915123\n15  ind_reca_fin_ult1  0.968925  0.918413\n16  ind_tjcr_fin_ult1  0.980335  0.952116\n17  ind_valo_fin_ult1   0.98664   0.88865\n18   ind_viv_fin_ult1   0.99725  0.984314\n19    ind_nomina_ult1   0.97414  0.863002\n20  ind_nom_pens_ult1  0.971976  0.825368\n21    ind_recibo_ult1  0.908935   0.58508","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Product</th>\n      <th>Accuracy</th>\n      <th>Precision</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>ind_cco_fin_ult1</td>\n      <td>0.773949</td>\n      <td>0.80987</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>ind_cder_fin_ult1</td>\n      <td>0.999751</td>\n      <td>0.992565</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>ind_cno_fin_ult1</td>\n      <td>0.954084</td>\n      <td>0.817844</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>ind_ctju_fin_ult1</td>\n      <td>0.999836</td>\n      <td>0.981554</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>ind_ctma_fin_ult1</td>\n      <td>0.992642</td>\n      <td>0.729721</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>ind_ctop_fin_ult1</td>\n      <td>0.901637</td>\n      <td>0.640403</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>ind_ctpp_fin_ult1</td>\n      <td>0.97212</td>\n      <td>0.647338</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>ind_deco_fin_ult1</td>\n      <td>0.998346</td>\n      <td>0.692992</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>ind_deme_fin_ult1</td>\n      <td>0.99882</td>\n      <td>0.988636</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>ind_dela_fin_ult1</td>\n      <td>0.972227</td>\n      <td>0.655142</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>ind_ecue_fin_ult1</td>\n      <td>0.946193</td>\n      <td>0.659859</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>ind_fond_fin_ult1</td>\n      <td>0.990089</td>\n      <td>0.930912</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>ind_hip_fin_ult1</td>\n      <td>0.997989</td>\n      <td>0.934673</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>ind_plan_fin_ult1</td>\n      <td>0.995895</td>\n      <td>0.951351</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>ind_pres_fin_ult1</td>\n      <td>0.998661</td>\n      <td>0.915123</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>ind_reca_fin_ult1</td>\n      <td>0.968925</td>\n      <td>0.918413</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>ind_tjcr_fin_ult1</td>\n      <td>0.980335</td>\n      <td>0.952116</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>ind_valo_fin_ult1</td>\n      <td>0.98664</td>\n      <td>0.88865</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>ind_viv_fin_ult1</td>\n      <td>0.99725</td>\n      <td>0.984314</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>ind_nomina_ult1</td>\n      <td>0.97414</td>\n      <td>0.863002</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>ind_nom_pens_ult1</td>\n      <td>0.971976</td>\n      <td>0.825368</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>ind_recibo_ult1</td>\n      <td>0.908935</td>\n      <td>0.58508</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"print(\"Overall train_accuracy across all products: \", scores.Accuracy.mean().round(3))\nprint(\"Overall train_precision across all products: \", scores.Precision.mean().round(3))","metadata":{"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"Overall train_accuracy across all products:  0.967\nOverall train_precision across all products:  0.835\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.metrics import classification_report\n# Generar informe de clasificación\nclassification_report = classification_report(y_test, y_pred, target_names=products)\n\n# Mostrar el informe de clasificación en un formato legible\nprint(\"Informe de clasificación:\\n\\n\", classification_report)","metadata":{"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"Informe de clasificación:\n\n                    precision    recall  f1-score   support\n\n ind_cco_fin_ult1       0.81      0.87      0.84   1219101\nind_cder_fin_ult1       1.00      0.21      0.35       575\n ind_cno_fin_ult1       0.79      0.01      0.01     83416\nind_ctju_fin_ult1       0.98      0.97      0.97      5999\nind_ctma_fin_ult1       0.71      0.28      0.40     16187\nind_ctop_fin_ult1       0.64      0.43      0.52    218352\nind_ctpp_fin_ult1       0.64      0.26      0.37     56603\nind_deco_fin_ult1       0.54      0.03      0.07      3121\nind_deme_fin_ult1       0.94      0.06      0.11      2296\nind_dela_fin_ult1       0.65      0.29      0.40     57853\nind_ecue_fin_ult1       0.66      0.15      0.24    104441\nind_fond_fin_ult1       0.88      0.02      0.03     18237\n ind_hip_fin_ult1       0.92      0.14      0.24      4164\nind_plan_fin_ult1       0.94      0.07      0.14      8188\nind_pres_fin_ult1       0.91      0.47      0.62      4234\nind_reca_fin_ult1       0.89      0.01      0.02     56564\nind_tjcr_fin_ult1       0.91      0.00      0.01     35966\nind_valo_fin_ult1       0.87      0.03      0.05     24449\n ind_viv_fin_ult1       0.97      0.04      0.07      5168\n  ind_nomina_ult1       0.80      0.00      0.01     47067\nind_nom_pens_ult1       0.76      0.00      0.01     50953\n  ind_recibo_ult1       0.58      0.07      0.13    167799\n\n        micro avg       0.78      0.56      0.65   2190733\n        macro avg       0.81      0.20      0.25   2190733\n     weighted avg       0.76      0.56      0.57   2190733\n      samples avg       0.60      0.54      0.55   2190733\n\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n","output_type":"stream"}]},{"cell_type":"code","source":"# Create a dataframe to store the scores\nscores = pd.DataFrame(columns = ['Product','Accuracy','Precision'])\nproducts = ['ind_cco_fin_ult1', 'ind_cder_fin_ult1', 'ind_cno_fin_ult1',\n       'ind_ctju_fin_ult1', 'ind_ctma_fin_ult1', 'ind_ctop_fin_ult1',\n       'ind_ctpp_fin_ult1', 'ind_deco_fin_ult1', 'ind_deme_fin_ult1',\n       'ind_dela_fin_ult1', 'ind_ecue_fin_ult1', 'ind_fond_fin_ult1',\n       'ind_hip_fin_ult1', 'ind_plan_fin_ult1', 'ind_pres_fin_ult1',\n       'ind_reca_fin_ult1', 'ind_tjcr_fin_ult1', 'ind_valo_fin_ult1',\n       'ind_viv_fin_ult1', 'ind_nomina_ult1', 'ind_nom_pens_ult1',\n       'ind_recibo_ult1']\nscores[\"Product\"] = products\n\n# Calculate the metrics for all classes at once\nfor i in range(22):\n  scores[\"Precision\"][i] = precision_score(y_test.iloc[:,i],y_pred.iloc[:,i])\n\nfor i in range(22):\n  scores[\"Accuracy\"][i] = accuracy_score(y_test.iloc[:,i],y_pred.iloc[:,i])\n\n# Print the scores dataframe\nscores","metadata":{"trusted":true},"execution_count":19,"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"              Product  Accuracy Precision\n0    ind_cco_fin_ult1  0.772892  0.808992\n1   ind_cder_fin_ult1  0.999747       1.0\n2    ind_cno_fin_ult1  0.953802  0.791842\n3   ind_ctju_fin_ult1  0.999804  0.975417\n4   ind_ctma_fin_ult1  0.992495  0.711052\n5   ind_ctop_fin_ult1  0.901259  0.638531\n6   ind_ctpp_fin_ult1  0.972102  0.641361\n7   ind_deco_fin_ult1  0.998272  0.539604\n8   ind_deme_fin_ult1   0.99879  0.942029\n9   ind_dela_fin_ult1  0.971985  0.646786\n10  ind_ecue_fin_ult1  0.945952  0.658281\n11  ind_fond_fin_ult1  0.989986  0.879257\n12   ind_hip_fin_ult1  0.997971  0.924714\n13  ind_plan_fin_ult1   0.99576  0.942636\n14  ind_pres_fin_ult1  0.998646  0.911375\n15  ind_reca_fin_ult1  0.968737  0.891089\n16  ind_tjcr_fin_ult1  0.980072  0.913265\n17  ind_valo_fin_ult1   0.98671  0.865557\n18   ind_viv_fin_ult1  0.997227  0.969697\n19    ind_nomina_ult1  0.973895       0.8\n20  ind_nom_pens_ult1  0.971716  0.759542\n21    ind_recibo_ult1  0.908531  0.580467","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Product</th>\n      <th>Accuracy</th>\n      <th>Precision</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>ind_cco_fin_ult1</td>\n      <td>0.772892</td>\n      <td>0.808992</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>ind_cder_fin_ult1</td>\n      <td>0.999747</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>ind_cno_fin_ult1</td>\n      <td>0.953802</td>\n      <td>0.791842</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>ind_ctju_fin_ult1</td>\n      <td>0.999804</td>\n      <td>0.975417</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>ind_ctma_fin_ult1</td>\n      <td>0.992495</td>\n      <td>0.711052</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>ind_ctop_fin_ult1</td>\n      <td>0.901259</td>\n      <td>0.638531</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>ind_ctpp_fin_ult1</td>\n      <td>0.972102</td>\n      <td>0.641361</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>ind_deco_fin_ult1</td>\n      <td>0.998272</td>\n      <td>0.539604</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>ind_deme_fin_ult1</td>\n      <td>0.99879</td>\n      <td>0.942029</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>ind_dela_fin_ult1</td>\n      <td>0.971985</td>\n      <td>0.646786</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>ind_ecue_fin_ult1</td>\n      <td>0.945952</td>\n      <td>0.658281</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>ind_fond_fin_ult1</td>\n      <td>0.989986</td>\n      <td>0.879257</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>ind_hip_fin_ult1</td>\n      <td>0.997971</td>\n      <td>0.924714</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>ind_plan_fin_ult1</td>\n      <td>0.99576</td>\n      <td>0.942636</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>ind_pres_fin_ult1</td>\n      <td>0.998646</td>\n      <td>0.911375</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>ind_reca_fin_ult1</td>\n      <td>0.968737</td>\n      <td>0.891089</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>ind_tjcr_fin_ult1</td>\n      <td>0.980072</td>\n      <td>0.913265</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>ind_valo_fin_ult1</td>\n      <td>0.98671</td>\n      <td>0.865557</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>ind_viv_fin_ult1</td>\n      <td>0.997227</td>\n      <td>0.969697</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>ind_nomina_ult1</td>\n      <td>0.973895</td>\n      <td>0.8</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>ind_nom_pens_ult1</td>\n      <td>0.971716</td>\n      <td>0.759542</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>ind_recibo_ult1</td>\n      <td>0.908531</td>\n      <td>0.580467</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"print(\"Overall test_accuracy across all products: \", scores.Accuracy.mean().round(3))\nprint(\"Overall test_precision across all products: \", scores.Precision.mean().round(3))","metadata":{"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"Overall test_accuracy across all products:  0.967\nOverall test_precision across all products:  0.809\n","output_type":"stream"}]},{"cell_type":"code","source":"# Accuracy top 3 \nsorted_scores = scores.sort_values(by='Accuracy', ascending=False)\ntop_3 = sorted_scores.head(3)\nprint(top_3)\nprint(f\"Mean top 3 accuracy: {top_3['Accuracy'].mean()}\") ","metadata":{"execution":{"iopub.status.busy":"2023-05-13T23:25:29.209765Z","iopub.execute_input":"2023-05-13T23:25:29.210557Z","iopub.status.idle":"2023-05-13T23:25:29.219213Z","shell.execute_reply.started":"2023-05-13T23:25:29.210523Z","shell.execute_reply":"2023-05-13T23:25:29.218352Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"             Product  Accuracy Precision\n3  ind_ctju_fin_ult1  0.999804  0.975417\n1  ind_cder_fin_ult1  0.999747       1.0\n8  ind_deme_fin_ult1   0.99879  0.942029\nMean top 3 accuracy: 0.9994469308745227\n","output_type":"stream"}]},{"cell_type":"code","source":"# Precision top 3 \nsorted_scores_p = scores.sort_values(by='Precision', ascending=False)\ntop_3 = sorted_scores_p.head(3)\nprint(top_3)\nprint(f\"Mean top 3 precision: {top_3['Precision'].mean()}\") ","metadata":{"execution":{"iopub.status.busy":"2023-05-13T23:25:33.085086Z","iopub.execute_input":"2023-05-13T23:25:33.085891Z","iopub.status.idle":"2023-05-13T23:25:33.095398Z","shell.execute_reply.started":"2023-05-13T23:25:33.085854Z","shell.execute_reply":"2023-05-13T23:25:33.094461Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stdout","text":"              Product  Accuracy Precision\n1   ind_cder_fin_ult1  0.999747       1.0\n3   ind_ctju_fin_ult1  0.999804  0.975417\n18   ind_viv_fin_ult1  0.997227  0.969697\nMean top 3 precision: 0.9817045688404503\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# **6.3.1 EVALUACIÓN DE MÉTRICAS OBTENIDAS**\n\nEs evidente que el modelo XGBoost ha demostrado una mejora significativa en términos de precisión en comparación con el primer modelo, incluso utilizando la configuración predeterminada. No solo ha aumentado la precisión general, sino también el accuracy, alcanzando valores de 0,81 y 0,97, respectivamente. Sin embargo, lo que más nos interesa es la precisión en el top 3, la cual ha mejorado considerablemente con un valor de 0,98. Además, el accuracy en los productos más recomendados también ha aumentado significativamente, alcanzando aproximadamente un 0,99. Esto nos permite afirmar con confianza que este modelo es una herramienta útil para recomendar con gran precisión los tres mejores productos a un cliente, lo que puede ser de gran ayuda para Santander en el próximo mes.\nNo obstante, todavía tenemos la oportunidad de mejorar el rendimiento de nuestro modelo mediante el hiperajuste, lo cual puede resultar en una precisión aún mayor.","metadata":{"id":"h1WoUNdJ0Xuf"}},{"cell_type":"markdown","source":"# **6.3.2 Ajuste de hiperparámetros para mejorar el modelo**\n\nPara mejorar aún más la precisión de nuestro modelo XGBoost, hemos implementado una técnica de optimización de hiperparámetros llamada GridSearch. Esta técnica se utiliza para recorrer sistemáticamente todas las combinaciones posibles de valores de hiperparámetros y encontrar la combinación óptima que produce los mejores resultados.\nAl utilizar GridSearch, podemos reducir significativamente el tiempo y la complejidad de la tarea de ajustar los hiperparámetros de nuestro modelo, ya que nos permite automatizar el proceso de búsqueda y selección de la mejor combinación de parámetros.\nEste enfoque nos permitirá obtener una mejor precisión en la clasificación de múltiples etiquetas en nuestro conjunto de datos, lo que puede ser especialmente útil para nuestro objetivo de recomendar los tres mejores productos a un cliente con gran precisión en el próximo mes.\nEn resumen, la implementación de GridSearch en nuestro modelo XGBoost es una estrategia clave para mejorar la eficiencia y precisión de nuestro proceso de ajuste de hiperparámetros, y puede ayudarnos a lograr mejores resultados en la clasificación de múltiples etiquetas y en la recomendación de productos a nuestros clientes. \nVamos a utilizar este método para encontrar el mejor modelo y obtener aún mejores resultados en la clasificación de múltiples etiquetas en nuestro conjunto de datos.","metadata":{"id":"xV_D06HZ0Xug"}},{"cell_type":"code","source":"clientes_modelado=clientes_modelado.sample(frac=0.01)","metadata":{"execution":{"iopub.status.busy":"2023-05-13T00:30:02.066240Z","iopub.execute_input":"2023-05-13T00:30:02.066675Z","iopub.status.idle":"2023-05-13T00:30:02.663421Z","shell.execute_reply.started":"2023-05-13T00:30:02.066644Z","shell.execute_reply":"2023-05-13T00:30:02.662386Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"#Separate independent and dependent variables\nX = clientes_modelado.iloc[:,0:16] #variables independientes\nY = clientes_modelado.iloc[:,16:38]    #target variable","metadata":{"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV\n...\nx_reduced = X[X.index % 2 == 0]\ny_reduced = Y[Y.index % 2 == 0]\n\n# Definimos los parámetros para hiperajustar nuestro modelo\nparameters = {\n    'estimator__learning_rate': [0.1, 0.2, 0.3, 0.4], # modifica la velocidad de aprendizaje\n    'estimator__max_depth': [6, 9, 12, 15] # modifica la profundidad del árbol\n}\n\n# Creamos una instancia del clasificador XGBoost y lo envolvemos en el MultiOutputClassifier\nxgboost_classifier = MultiOutputClassifier(estimator=XGBClassifier())\n\n# Creamos una instancia de GridSearchCV para hiperajustar nuestro modelo\ngrid = GridSearchCV(\n    estimator=xgboost_classifier, \n    param_grid=parameters, cv=3, n_jobs=-1, scoring=\"precision_weighted\"\n)\nprint(\"Ajustando modelo...\")\n# Ajustamos el modelo a nuestros datos reducidos\ngrid.fit(x_reduced, y_reduced)\n\n# Obtenemos los mejores valores para los parámetros que definimos\nbest_learning_rate = grid.best_params_[\"estimator__learning_rate\"] \nbest_max_depth = grid.best_params_[\"estimator__max_depth\"] ","metadata":{"execution":{"iopub.status.busy":"2023-05-13T00:45:56.971518Z","iopub.execute_input":"2023-05-13T00:45:56.972409Z","iopub.status.idle":"2023-05-13T00:53:05.512158Z","shell.execute_reply.started":"2023-05-13T00:45:56.972362Z","shell.execute_reply":"2023-05-13T00:53:05.510792Z"},"trusted":true},"execution_count":33,"outputs":[{"name":"stdout","text":"Ajustando modelo...\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n","output_type":"stream"}]},{"cell_type":"code","source":"best_learning_rate = grid.best_params_[\"estimator__learning_rate\"] \nbest_max_depth = grid.best_params_[\"estimator__max_depth\"] \nbest_score = grid.best_score_\n\nprint(\"best_learning_rate:\", best_learning_rate)\nprint(\"best_max_depth:\", best_max_depth)\nprint(\"best_score:\", best_score)","metadata":{"execution":{"iopub.status.busy":"2023-05-13T00:55:16.871275Z","iopub.execute_input":"2023-05-13T00:55:16.872264Z","iopub.status.idle":"2023-05-13T00:55:16.877880Z","shell.execute_reply.started":"2023-05-13T00:55:16.872228Z","shell.execute_reply":"2023-05-13T00:55:16.877017Z"},"trusted":true},"execution_count":35,"outputs":[{"name":"stdout","text":"best_learning_rate: 0.1\nbest_max_depth: 9\nbest_score: 0.6607510295615953\n","output_type":"stream"}]},{"cell_type":"code","source":"# Dividir los datos en entrenamiento y prueba\nx_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.3, random_state=42)\n\n# Entrenar un clasificador XGBoost utilizando los mejores parámetros obtenidos\nxgboost_classifier = MultiOutputClassifier(estimator=XGBClassifier(learning_rate=best_learning_rate, max_depth=best_max_depth))\nxgboost_classifier.fit(x_train, y_train)\n\n# Realizar predicciones sobre los datos de entrenamiento\ny_train_pred_xgb = xgboost_classifier.predict(x_train)\n\n# Convertir las predicciones a un DataFrame de pandas\ny_train_pred_xgb = pd.DataFrame(y_train_pred_xgb, columns=y_train.columns)\n\n# Comprobar que las dimensiones son correctas\nprint(\"Dimensiones de y_train_pred_xgb:\", y_train_pred_xgb.shape)\n# Realizar predicciones sobre el conjunto de prueba\ny_pred = pd.DataFrame(xgboost_classifier.predict(x_test))\n","metadata":{"execution":{"iopub.status.busy":"2023-05-13T01:04:31.765646Z","iopub.execute_input":"2023-05-13T01:04:31.766418Z","iopub.status.idle":"2023-05-13T01:07:24.940882Z","shell.execute_reply.started":"2023-05-13T01:04:31.766379Z","shell.execute_reply":"2023-05-13T01:07:24.936174Z"},"trusted":true},"execution_count":42,"outputs":[{"name":"stdout","text":"Dimensiones de y_train_pred_xgb: (89831, 22)\n","output_type":"stream"}]},{"cell_type":"code","source":"y_train_pred_xgb","metadata":{"execution":{"iopub.status.busy":"2023-05-13T01:07:30.961818Z","iopub.execute_input":"2023-05-13T01:07:30.962818Z","iopub.status.idle":"2023-05-13T01:07:30.991304Z","shell.execute_reply.started":"2023-05-13T01:07:30.962780Z","shell.execute_reply":"2023-05-13T01:07:30.990533Z"},"trusted":true},"execution_count":43,"outputs":[{"execution_count":43,"output_type":"execute_result","data":{"text/plain":"       ind_cco_fin_ult1  ind_cder_fin_ult1  ind_cno_fin_ult1   \n0                     0                  0                 0  \\\n1                     0                  0                 0   \n2                     0                  0                 0   \n3                     1                  0                 0   \n4                     1                  0                 0   \n...                 ...                ...               ...   \n89826                 1                  0                 0   \n89827                 1                  0                 0   \n89828                 1                  0                 0   \n89829                 1                  0                 0   \n89830                 0                  0                 0   \n\n       ind_ctju_fin_ult1  ind_ctma_fin_ult1  ind_ctop_fin_ult1   \n0                      0                  0                  0  \\\n1                      0                  0                  0   \n2                      0                  0                  0   \n3                      0                  0                  0   \n4                      0                  0                  0   \n...                  ...                ...                ...   \n89826                  0                  0                  0   \n89827                  0                  0                  1   \n89828                  0                  0                  0   \n89829                  0                  0                  1   \n89830                  0                  0                  0   \n\n       ind_ctpp_fin_ult1  ind_deco_fin_ult1  ind_deme_fin_ult1   \n0                      0                  0                  0  \\\n1                      0                  0                  0   \n2                      0                  0                  0   \n3                      0                  0                  0   \n4                      0                  0                  0   \n...                  ...                ...                ...   \n89826                  0                  0                  0   \n89827                  0                  0                  0   \n89828                  0                  0                  0   \n89829                  0                  0                  0   \n89830                  0                  0                  0   \n\n       ind_dela_fin_ult1  ...  ind_hip_fin_ult1  ind_plan_fin_ult1   \n0                      0  ...                 0                  0  \\\n1                      0  ...                 0                  0   \n2                      0  ...                 0                  0   \n3                      0  ...                 0                  0   \n4                      0  ...                 0                  0   \n...                  ...  ...               ...                ...   \n89826                  0  ...                 0                  0   \n89827                  0  ...                 0                  0   \n89828                  0  ...                 0                  0   \n89829                  0  ...                 0                  0   \n89830                  0  ...                 0                  0   \n\n       ind_pres_fin_ult1  ind_reca_fin_ult1  ind_tjcr_fin_ult1   \n0                      0                  0                  0  \\\n1                      0                  0                  0   \n2                      0                  0                  0   \n3                      0                  0                  0   \n4                      0                  0                  0   \n...                  ...                ...                ...   \n89826                  0                  0                  0   \n89827                  0                  0                  0   \n89828                  0                  0                  0   \n89829                  0                  0                  0   \n89830                  0                  0                  0   \n\n       ind_valo_fin_ult1  ind_viv_fin_ult1  ind_nomina_ult1   \n0                      0                 0                0  \\\n1                      0                 0                0   \n2                      0                 0                0   \n3                      0                 0                0   \n4                      0                 0                0   \n...                  ...               ...              ...   \n89826                  0                 0                0   \n89827                  0                 0                0   \n89828                  0                 0                0   \n89829                  0                 0                0   \n89830                  0                 0                0   \n\n       ind_nom_pens_ult1  ind_recibo_ult1  \n0                      0                0  \n1                      0                0  \n2                      0                0  \n3                      0                0  \n4                      0                0  \n...                  ...              ...  \n89826                  0                0  \n89827                  0                0  \n89828                  0                0  \n89829                  0                0  \n89830                  0                0  \n\n[89831 rows x 22 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ind_cco_fin_ult1</th>\n      <th>ind_cder_fin_ult1</th>\n      <th>ind_cno_fin_ult1</th>\n      <th>ind_ctju_fin_ult1</th>\n      <th>ind_ctma_fin_ult1</th>\n      <th>ind_ctop_fin_ult1</th>\n      <th>ind_ctpp_fin_ult1</th>\n      <th>ind_deco_fin_ult1</th>\n      <th>ind_deme_fin_ult1</th>\n      <th>ind_dela_fin_ult1</th>\n      <th>...</th>\n      <th>ind_hip_fin_ult1</th>\n      <th>ind_plan_fin_ult1</th>\n      <th>ind_pres_fin_ult1</th>\n      <th>ind_reca_fin_ult1</th>\n      <th>ind_tjcr_fin_ult1</th>\n      <th>ind_valo_fin_ult1</th>\n      <th>ind_viv_fin_ult1</th>\n      <th>ind_nomina_ult1</th>\n      <th>ind_nom_pens_ult1</th>\n      <th>ind_recibo_ult1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>89826</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>89827</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>89828</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>89829</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>89830</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>89831 rows × 22 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"y_pred","metadata":{"execution":{"iopub.status.busy":"2023-05-13T01:07:37.213277Z","iopub.execute_input":"2023-05-13T01:07:37.214225Z","iopub.status.idle":"2023-05-13T01:07:37.236971Z","shell.execute_reply.started":"2023-05-13T01:07:37.214185Z","shell.execute_reply":"2023-05-13T01:07:37.236246Z"},"trusted":true},"execution_count":44,"outputs":[{"execution_count":44,"output_type":"execute_result","data":{"text/plain":"       0   1   2   3   4   5   6   7   8   9   ...  12  13  14  15  16  17   \n0       0   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   0  \\\n1       0   0   0   0   0   1   0   0   0   0  ...   0   0   0   0   0   0   \n2       1   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   \n3       1   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   \n4       0   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   \n...    ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ...  ..  ..  ..  ..  ..  ..   \n38495   1   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   \n38496   1   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   \n38497   1   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   \n38498   0   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   \n38499   1   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   \n\n       18  19  20  21  \n0       0   0   0   0  \n1       0   0   0   0  \n2       0   0   0   0  \n3       0   0   0   0  \n4       0   0   0   0  \n...    ..  ..  ..  ..  \n38495   0   0   0   0  \n38496   0   0   0   0  \n38497   0   0   0   0  \n38498   0   0   0   0  \n38499   0   0   0   0  \n\n[38500 rows x 22 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>...</th>\n      <th>12</th>\n      <th>13</th>\n      <th>14</th>\n      <th>15</th>\n      <th>16</th>\n      <th>17</th>\n      <th>18</th>\n      <th>19</th>\n      <th>20</th>\n      <th>21</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>38495</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>38496</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>38497</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>38498</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>38499</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>38500 rows × 22 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n\n# Create a dataframe to store the scores\nscores = pd.DataFrame(columns = ['Product','Accuracy','Precision'])\nproducts = ['ind_cco_fin_ult1', 'ind_cder_fin_ult1', 'ind_cno_fin_ult1',\n       'ind_ctju_fin_ult1', 'ind_ctma_fin_ult1', 'ind_ctop_fin_ult1',\n       'ind_ctpp_fin_ult1', 'ind_deco_fin_ult1', 'ind_deme_fin_ult1',\n       'ind_dela_fin_ult1', 'ind_ecue_fin_ult1', 'ind_fond_fin_ult1',\n       'ind_hip_fin_ult1', 'ind_plan_fin_ult1', 'ind_pres_fin_ult1',\n       'ind_reca_fin_ult1', 'ind_tjcr_fin_ult1', 'ind_valo_fin_ult1',\n       'ind_viv_fin_ult1', 'ind_nomina_ult1', 'ind_nom_pens_ult1',\n       'ind_recibo_ult1']\nscores[\"Product\"] = products\n\n# Calculate the metrics for all classes at once\nfor i in range(22):\n  scores[\"Precision\"][i] = precision_score(y_train.iloc[:,i],y_train_pred_xgb.iloc[:,i])\n\nfor i in range(22):\n  scores[\"Accuracy\"][i] = accuracy_score(y_train.iloc[:,i],y_train_pred_xgb.iloc[:,i])\n\n# Print the scores dataframe\nscores\n#overall","metadata":{"execution":{"iopub.status.busy":"2023-05-13T01:07:47.167899Z","iopub.execute_input":"2023-05-13T01:07:47.169002Z","iopub.status.idle":"2023-05-13T01:07:47.865891Z","shell.execute_reply.started":"2023-05-13T01:07:47.168959Z","shell.execute_reply":"2023-05-13T01:07:47.864881Z"},"trusted":true},"execution_count":45,"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n","output_type":"stream"},{"execution_count":45,"output_type":"execute_result","data":{"text/plain":"              Product  Accuracy Precision\n0    ind_cco_fin_ult1  0.796585  0.825857\n1   ind_cder_fin_ult1  0.999733       0.0\n2    ind_cno_fin_ult1  0.958288  0.975309\n3   ind_ctju_fin_ult1  0.999944       1.0\n4   ind_ctma_fin_ult1  0.995347    0.9375\n5   ind_ctop_fin_ult1   0.90835  0.686392\n6   ind_ctpp_fin_ult1  0.978448  0.809291\n7   ind_deco_fin_ult1  0.999054       1.0\n8   ind_deme_fin_ult1  0.998464       1.0\n9   ind_dela_fin_ult1  0.976456  0.764666\n10  ind_ecue_fin_ult1  0.947412  0.802342\n11  ind_fond_fin_ult1  0.989514       1.0\n12   ind_hip_fin_ult1  0.998174       1.0\n13  ind_plan_fin_ult1  0.994991       1.0\n14  ind_pres_fin_ult1  0.998553  0.981132\n15  ind_reca_fin_ult1  0.970868       1.0\n16  ind_tjcr_fin_ult1  0.977124       1.0\n17  ind_valo_fin_ult1  0.985094  0.977778\n18   ind_viv_fin_ult1  0.997184       1.0\n19    ind_nomina_ult1  0.979105       1.0\n20  ind_nom_pens_ult1   0.97709       1.0\n21    ind_recibo_ult1  0.913326  0.758829","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Product</th>\n      <th>Accuracy</th>\n      <th>Precision</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>ind_cco_fin_ult1</td>\n      <td>0.796585</td>\n      <td>0.825857</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>ind_cder_fin_ult1</td>\n      <td>0.999733</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>ind_cno_fin_ult1</td>\n      <td>0.958288</td>\n      <td>0.975309</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>ind_ctju_fin_ult1</td>\n      <td>0.999944</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>ind_ctma_fin_ult1</td>\n      <td>0.995347</td>\n      <td>0.9375</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>ind_ctop_fin_ult1</td>\n      <td>0.90835</td>\n      <td>0.686392</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>ind_ctpp_fin_ult1</td>\n      <td>0.978448</td>\n      <td>0.809291</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>ind_deco_fin_ult1</td>\n      <td>0.999054</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>ind_deme_fin_ult1</td>\n      <td>0.998464</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>ind_dela_fin_ult1</td>\n      <td>0.976456</td>\n      <td>0.764666</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>ind_ecue_fin_ult1</td>\n      <td>0.947412</td>\n      <td>0.802342</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>ind_fond_fin_ult1</td>\n      <td>0.989514</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>ind_hip_fin_ult1</td>\n      <td>0.998174</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>ind_plan_fin_ult1</td>\n      <td>0.994991</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>ind_pres_fin_ult1</td>\n      <td>0.998553</td>\n      <td>0.981132</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>ind_reca_fin_ult1</td>\n      <td>0.970868</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>ind_tjcr_fin_ult1</td>\n      <td>0.977124</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>ind_valo_fin_ult1</td>\n      <td>0.985094</td>\n      <td>0.977778</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>ind_viv_fin_ult1</td>\n      <td>0.997184</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>ind_nomina_ult1</td>\n      <td>0.979105</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>ind_nom_pens_ult1</td>\n      <td>0.97709</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>ind_recibo_ult1</td>\n      <td>0.913326</td>\n      <td>0.758829</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"print(\"Overall train_accuracy across all products: \", scores.Accuracy.mean().round(3))\nprint(\"Overall train_precision across all products: \", scores.Precision.mean().round(3))","metadata":{"execution":{"iopub.status.busy":"2023-05-13T01:07:55.463435Z","iopub.execute_input":"2023-05-13T01:07:55.464359Z","iopub.status.idle":"2023-05-13T01:07:55.470605Z","shell.execute_reply.started":"2023-05-13T01:07:55.464323Z","shell.execute_reply":"2023-05-13T01:07:55.469774Z"},"trusted":true},"execution_count":46,"outputs":[{"name":"stdout","text":"Overall train_accuracy across all products:  0.97\nOverall train_precision across all products:  0.887\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.metrics import classification_report\n# Generar informe de clasificación\nclassification_report = classification_report(y_test, y_pred, target_names=products)\n\n# Mostrar el informe de clasificación en un formato legible\nprint(\"Informe de clasificación:\\n\\n\", classification_report)","metadata":{"execution":{"iopub.status.busy":"2023-05-13T01:07:59.206003Z","iopub.execute_input":"2023-05-13T01:07:59.207006Z","iopub.status.idle":"2023-05-13T01:07:59.334761Z","shell.execute_reply.started":"2023-05-13T01:07:59.206968Z","shell.execute_reply":"2023-05-13T01:07:59.333781Z"},"trusted":true},"execution_count":47,"outputs":[{"name":"stdout","text":"Informe de clasificación:\n\n                    precision    recall  f1-score   support\n\n ind_cco_fin_ult1       0.81      0.87      0.84     26244\nind_cder_fin_ult1       0.00      0.00      0.00        11\n ind_cno_fin_ult1       0.12      0.00      0.00      1637\nind_ctju_fin_ult1       0.92      0.93      0.92       126\nind_ctma_fin_ult1       0.61      0.26      0.37       347\nind_ctop_fin_ult1       0.60      0.42      0.50      4741\nind_ctpp_fin_ult1       0.56      0.21      0.31      1208\nind_deco_fin_ult1       0.20      0.03      0.06        62\nind_deme_fin_ult1       0.00      0.00      0.00        47\nind_dela_fin_ult1       0.64      0.30      0.41      1352\nind_ecue_fin_ult1       0.61      0.13      0.21      2463\nind_fond_fin_ult1       0.57      0.01      0.02       454\n ind_hip_fin_ult1       1.00      0.03      0.06        98\nind_plan_fin_ult1       0.33      0.01      0.02       205\nind_pres_fin_ult1       0.75      0.31      0.44        87\nind_reca_fin_ult1       0.75      0.00      0.01      1201\nind_tjcr_fin_ult1       0.33      0.00      0.00       921\nind_valo_fin_ult1       0.40      0.01      0.01       630\n ind_viv_fin_ult1       1.00      0.01      0.02       127\n  ind_nomina_ult1       0.00      0.00      0.00       812\nind_nom_pens_ult1       0.50      0.00      0.00       908\n  ind_recibo_ult1       0.50      0.06      0.11      3568\n\n        micro avg       0.78      0.56      0.65     47249\n        macro avg       0.51      0.16      0.20     47249\n     weighted avg       0.68      0.56      0.56     47249\n      samples avg       0.60      0.53      0.55     47249\n\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n","output_type":"stream"}]},{"cell_type":"code","source":"# Create a dataframe to store the scores\nscores = pd.DataFrame(columns = ['Product','Accuracy','Precision'])\nproducts = ['ind_cco_fin_ult1', 'ind_cder_fin_ult1', 'ind_cno_fin_ult1',\n       'ind_ctju_fin_ult1', 'ind_ctma_fin_ult1', 'ind_ctop_fin_ult1',\n       'ind_ctpp_fin_ult1', 'ind_deco_fin_ult1', 'ind_deme_fin_ult1',\n       'ind_dela_fin_ult1', 'ind_ecue_fin_ult1', 'ind_fond_fin_ult1',\n       'ind_hip_fin_ult1', 'ind_plan_fin_ult1', 'ind_pres_fin_ult1',\n       'ind_reca_fin_ult1', 'ind_tjcr_fin_ult1', 'ind_valo_fin_ult1',\n       'ind_viv_fin_ult1', 'ind_nomina_ult1', 'ind_nom_pens_ult1',\n       'ind_recibo_ult1']\nscores[\"Product\"] = products\n\n# Calculate the metrics for all classes at once\nfor i in range(22):\n  scores[\"Precision\"][i] = precision_score(y_test.iloc[:,i],y_pred.iloc[:,i])\n\nfor i in range(22):\n  scores[\"Accuracy\"][i] = accuracy_score(y_test.iloc[:,i],y_pred.iloc[:,i])\n\n# Print the scores dataframe\nscores","metadata":{"execution":{"iopub.status.busy":"2023-05-13T01:08:06.531770Z","iopub.execute_input":"2023-05-13T01:08:06.532660Z","iopub.status.idle":"2023-05-13T01:08:06.859511Z","shell.execute_reply.started":"2023-05-13T01:08:06.532625Z","shell.execute_reply":"2023-05-13T01:08:06.858720Z"},"trusted":true},"execution_count":48,"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n","output_type":"stream"},{"execution_count":48,"output_type":"execute_result","data":{"text/plain":"              Product  Accuracy Precision\n0    ind_cco_fin_ult1  0.775299  0.812276\n1   ind_cder_fin_ult1  0.999714       0.0\n2    ind_cno_fin_ult1  0.957169     0.125\n3   ind_ctju_fin_ult1  0.999506   0.92126\n4   ind_ctma_fin_ult1   0.99187  0.614865\n5   ind_ctop_fin_ult1  0.894753   0.60411\n6   ind_ctpp_fin_ult1  0.969974  0.556277\n7   ind_deco_fin_ult1  0.998234       0.2\n8   ind_deme_fin_ult1  0.998779       0.0\n9   ind_dela_fin_ult1  0.969506  0.640379\n10  ind_ecue_fin_ult1  0.939065  0.612717\n11  ind_fond_fin_ult1  0.988234  0.571429\n12   ind_hip_fin_ult1  0.997532       1.0\n13  ind_plan_fin_ult1  0.994623  0.333333\n14  ind_pres_fin_ult1  0.998208      0.75\n15  ind_reca_fin_ult1  0.968909      0.75\n16  ind_tjcr_fin_ult1  0.976052  0.333333\n17  ind_valo_fin_ult1  0.983584       0.4\n18   ind_viv_fin_ult1  0.996727       1.0\n19    ind_nomina_ult1  0.978909       0.0\n20  ind_nom_pens_ult1  0.976416       0.5\n21    ind_recibo_ult1  0.907377  0.502283","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Product</th>\n      <th>Accuracy</th>\n      <th>Precision</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>ind_cco_fin_ult1</td>\n      <td>0.775299</td>\n      <td>0.812276</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>ind_cder_fin_ult1</td>\n      <td>0.999714</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>ind_cno_fin_ult1</td>\n      <td>0.957169</td>\n      <td>0.125</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>ind_ctju_fin_ult1</td>\n      <td>0.999506</td>\n      <td>0.92126</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>ind_ctma_fin_ult1</td>\n      <td>0.99187</td>\n      <td>0.614865</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>ind_ctop_fin_ult1</td>\n      <td>0.894753</td>\n      <td>0.60411</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>ind_ctpp_fin_ult1</td>\n      <td>0.969974</td>\n      <td>0.556277</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>ind_deco_fin_ult1</td>\n      <td>0.998234</td>\n      <td>0.2</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>ind_deme_fin_ult1</td>\n      <td>0.998779</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>ind_dela_fin_ult1</td>\n      <td>0.969506</td>\n      <td>0.640379</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>ind_ecue_fin_ult1</td>\n      <td>0.939065</td>\n      <td>0.612717</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>ind_fond_fin_ult1</td>\n      <td>0.988234</td>\n      <td>0.571429</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>ind_hip_fin_ult1</td>\n      <td>0.997532</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>ind_plan_fin_ult1</td>\n      <td>0.994623</td>\n      <td>0.333333</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>ind_pres_fin_ult1</td>\n      <td>0.998208</td>\n      <td>0.75</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>ind_reca_fin_ult1</td>\n      <td>0.968909</td>\n      <td>0.75</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>ind_tjcr_fin_ult1</td>\n      <td>0.976052</td>\n      <td>0.333333</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>ind_valo_fin_ult1</td>\n      <td>0.983584</td>\n      <td>0.4</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>ind_viv_fin_ult1</td>\n      <td>0.996727</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>ind_nomina_ult1</td>\n      <td>0.978909</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>ind_nom_pens_ult1</td>\n      <td>0.976416</td>\n      <td>0.5</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>ind_recibo_ult1</td>\n      <td>0.907377</td>\n      <td>0.502283</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"print(\"Overall test_accuracy across all products: \", scores.Accuracy.mean().round(3))\nprint(\"Overall test_precision across all products: \", scores.Precision.mean().round(3))","metadata":{"execution":{"iopub.status.busy":"2023-05-13T01:08:11.422738Z","iopub.execute_input":"2023-05-13T01:08:11.423451Z","iopub.status.idle":"2023-05-13T01:08:11.429877Z","shell.execute_reply.started":"2023-05-13T01:08:11.423414Z","shell.execute_reply":"2023-05-13T01:08:11.429082Z"},"trusted":true},"execution_count":49,"outputs":[{"name":"stdout","text":"Overall test_accuracy across all products:  0.966\nOverall test_precision across all products:  0.51\n","output_type":"stream"}]},{"cell_type":"code","source":"# Accuracy top 3 \nsorted_scores = scores.sort_values(by='Accuracy', ascending=False)\ntop_3 = sorted_scores.head(3)\nprint(top_3)\nprint(f\"Mean top 3 accuracy: {top_3['Accuracy'].mean()}\") ","metadata":{"execution":{"iopub.status.busy":"2023-05-13T01:08:19.129966Z","iopub.execute_input":"2023-05-13T01:08:19.130440Z","iopub.status.idle":"2023-05-13T01:08:19.140478Z","shell.execute_reply.started":"2023-05-13T01:08:19.130405Z","shell.execute_reply":"2023-05-13T01:08:19.139480Z"},"trusted":true},"execution_count":50,"outputs":[{"name":"stdout","text":"             Product  Accuracy Precision\n1  ind_cder_fin_ult1  0.999714       0.0\n3  ind_ctju_fin_ult1  0.999506   0.92126\n8  ind_deme_fin_ult1  0.998779       0.0\nMean top 3 accuracy: 0.9993333333333334\n","output_type":"stream"}]},{"cell_type":"code","source":"# Precision top 3 \nsorted_scores_p = scores.sort_values(by='Precision', ascending=False)\ntop_3 = sorted_scores_p.head(3)\nprint(top_3)\nprint(f\"Mean top 3 accuracy: {top_3['Precision'].mean()}\") ","metadata":{"execution":{"iopub.status.busy":"2023-05-13T01:08:22.723189Z","iopub.execute_input":"2023-05-13T01:08:22.723577Z","iopub.status.idle":"2023-05-13T01:08:22.732789Z","shell.execute_reply.started":"2023-05-13T01:08:22.723547Z","shell.execute_reply":"2023-05-13T01:08:22.731989Z"},"trusted":true},"execution_count":51,"outputs":[{"name":"stdout","text":"              Product  Accuracy Precision\n18   ind_viv_fin_ult1  0.996727       1.0\n12   ind_hip_fin_ult1  0.997532       1.0\n3   ind_ctju_fin_ult1  0.999506   0.92126\nMean top 3 accuracy: 0.9737532808398951\n","output_type":"stream"}]},{"cell_type":"code","source":"MatrizDecision = pd.DataFrame({'Overall test_accuracy across all products': [0.967, 0.966],\n                   'Overall test_precision across all products': [0.81, 0.51],\n                   'Mean top 3 accuracy': [0.999, 0.999],\n                   'Mean top 3 precision': [0.985, 0.973]\n                   })\nMatrizDecision.index = ['XGBoost con parámetros predeterminados', 'XGBoost con hiperparámetros']\n\nprint(MatrizDecision)","metadata":{"execution":{"iopub.status.busy":"2023-05-13T23:26:14.276740Z","iopub.execute_input":"2023-05-13T23:26:14.277448Z","iopub.status.idle":"2023-05-13T23:26:14.288923Z","shell.execute_reply.started":"2023-05-13T23:26:14.277411Z","shell.execute_reply":"2023-05-13T23:26:14.287978Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stdout","text":"                                        Overall test_accuracy across all products   \nXGBoost con parámetros predeterminados                                      0.967  \\\nXGBoost con hiperparámetros                                                 0.966   \n\n                                        Overall test_precision across all products   \nXGBoost con parámetros predeterminados                                        0.81  \\\nXGBoost con hiperparámetros                                                   0.51   \n\n                                        Mean top 3 accuracy   \nXGBoost con parámetros predeterminados                0.999  \\\nXGBoost con hiperparámetros                           0.999   \n\n                                        Mean top 3 precision  \nXGBoost con parámetros predeterminados                 0.985  \nXGBoost con hiperparámetros                            0.973  \n","output_type":"stream"}]},{"cell_type":"markdown","source":"**Después de realizar la GridSearch exhaustiva utilizando los parámetros seleccionados, nos encontramos con que el puntaje obtenido con los mejores parámetros no superó a los resultados obtenidos con los parámetros predeterminados. De hecho, la precisión general disminuyó a 0,51, lo que indica que los parámetros seleccionados no lograron mejorar significativamente la calidad del modelo. Además, la búsqueda de parámetros consumió un tiempo considerable, lo que afectó la eficiencia del proceso de ajuste del modelo.\nDespués de esta evaluación, decidimos continuar utilizando los parámetros predeterminados en nuestro modelo XGBoost. Aunque la búsqueda de parámetros no arrojó los resultados deseados, esto no significa que debamos descartar la posibilidad de utilizar parámetros personalizados en el futuro. El proceso de hiperajuste es un proceso iterativo y siempre podemos volver a examinar estos parámetros en el futuro para obtener una mayor precisión en la clasificación de múltiples etiquetas en nuestro conjunto de datos..**","metadata":{"id":"1yz0Pa-w0Xuh"}},{"cell_type":"markdown","source":"# **6.3.3 Permutarion importance**\n","metadata":{"id":"9XAz-aAm0Xuh"}},{"cell_type":"markdown","source":"**Ahora vamos a utilizar la técnica de Permutation Importance para determinar qué características son más importantes a la hora de recomendar productos a nuestros clientes. Esta técnica consiste en evaluar el rendimiento del modelo al permutar los valores de una característica, y observar el cambio en la precisión del modelo. Cuanto mayor sea el cambio en la precisión, mayor será la importancia de esa característica.\nLa importancia de permutación es una técnica útil para evaluar la importancia relativa de las características en un modelo. A diferencia de otros métodos, como la importancia de la característica basada en el modelo, la importancia de permutación no se basa en la construcción de un modelo separado para cada característica. En su lugar, utiliza el modelo original y mide la importancia de cada característica a través de la aleatorización y la evaluación del rendimiento del modelo.**","metadata":{}},{"cell_type":"code","source":"#Separate independent and dependent variables\nX = clientes_modelado.iloc[:,0:16] #variables independientes\nY = clientes_modelado.iloc[:,16:38]    #target variable","metadata":{"execution":{"iopub.status.busy":"2023-05-13T01:10:37.971855Z","iopub.execute_input":"2023-05-13T01:10:37.972403Z","iopub.status.idle":"2023-05-13T01:10:37.992023Z","shell.execute_reply.started":"2023-05-13T01:10:37.972365Z","shell.execute_reply":"2023-05-13T01:10:37.991049Z"},"trusted":true},"execution_count":53,"outputs":[]},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, Y, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2023-05-13T01:10:40.638144Z","iopub.execute_input":"2023-05-13T01:10:40.639051Z","iopub.status.idle":"2023-05-13T01:10:40.692158Z","shell.execute_reply.started":"2023-05-13T01:10:40.639015Z","shell.execute_reply":"2023-05-13T01:10:40.690943Z"},"trusted":true},"execution_count":54,"outputs":[]},{"cell_type":"code","source":"# Importar la librería Permutation Importance\nfrom sklearn.inspection import permutation_importance\n\n# Entrenar el modelo XGBoost\nxgboost_classifier = MultiOutputClassifier(estimator=XGBClassifier())\nxgboost_classifier.fit(X_train, y_train)\n\n# Realizar predicciones sobre los datos de entrenamiento\ny_train_pred = xgboost_classifier.predict(X_train)\ny_train_pred = pd.DataFrame(y_train_pred)\n\n# Calcular Permutation Importance\nresult = permutation_importance(xgboost_classifier, X_train, y_train, n_repeats=10, random_state=42)\n\n# Obtener la importancia de cada característica\nimportance = result.importances_mean\n\n# Graficar la importancia de cada característica\nimportance_df = pd.DataFrame({'feature': X_train.columns, 'importance': importance})\nimportance_df.sort_values(by='importance', ascending=False, inplace=True)\nplt.figure(figsize=(10,8))\nplt.barh(importance_df['feature'], importance_df['importance'], color=['teal', 'indianred', 'royalblue', 'darkviolet','royalblue','bisque','lightcoral', 'crimson', 'lightgreen','slategray','peru'])\nplt.title('Permutation Importance', fontsize=18)\nplt.xlabel('Importance', fontsize=14)\nplt.ylabel('Feature', fontsize=14)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-05-13T01:15:58.026749Z","iopub.execute_input":"2023-05-13T01:15:58.027201Z","iopub.status.idle":"2023-05-13T01:19:27.431577Z","shell.execute_reply.started":"2023-05-13T01:15:58.027150Z","shell.execute_reply":"2023-05-13T01:19:27.430688Z"},"trusted":true},"execution_count":58,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 1000x800 with 1 Axes>","image/png":"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"},"metadata":{}}]},{"cell_type":"code","source":"importance_df","metadata":{"execution":{"iopub.status.busy":"2023-05-13T01:19:45.026306Z","iopub.execute_input":"2023-05-13T01:19:45.027318Z","iopub.status.idle":"2023-05-13T01:19:45.041379Z","shell.execute_reply.started":"2023-05-13T01:19:45.027249Z","shell.execute_reply":"2023-05-13T01:19:45.040134Z"},"trusted":true},"execution_count":59,"outputs":[{"execution_count":59,"output_type":"execute_result","data":{"text/plain":"                  feature  importance\n4              fecha_alta    0.105017\n13  ind_actividad_cliente    0.096850\n0                ncodpers    0.091369\n3                     age    0.068553\n11          canal_entrada    0.056948\n15               segmento    0.033811\n14                  renta    0.030160\n8             tiprel_1mes    0.014834\n2                    sexo    0.003994\n5               ind_nuevo    0.003416\n10                 indext    0.001988\n6                  indrel    0.001294\n9                 indresi    0.000512\n12                indfall    0.000183\n7             indrel_1mes    0.000160\n1            ind_empleado    0.000024","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>feature</th>\n      <th>importance</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>4</th>\n      <td>fecha_alta</td>\n      <td>0.105017</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>ind_actividad_cliente</td>\n      <td>0.096850</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>ncodpers</td>\n      <td>0.091369</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>age</td>\n      <td>0.068553</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>canal_entrada</td>\n      <td>0.056948</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>segmento</td>\n      <td>0.033811</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>renta</td>\n      <td>0.030160</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>tiprel_1mes</td>\n      <td>0.014834</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>sexo</td>\n      <td>0.003994</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>ind_nuevo</td>\n      <td>0.003416</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>indext</td>\n      <td>0.001988</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>indrel</td>\n      <td>0.001294</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>indresi</td>\n      <td>0.000512</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>indfall</td>\n      <td>0.000183</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>indrel_1mes</td>\n      <td>0.000160</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>ind_empleado</td>\n      <td>0.000024</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"**Observaciones**:\n\nEl análisis de Permutation Importance en el modelo XGBoost proporciona información sobre la importancia relativa de cada variable en la predicción del resultado. En este caso, se observa que la variable más importante es \"fecha_alta\" con un valor de importancia de 0.105, seguida de \"ind_actividad_cliente\" con 0.097 y \"ncodpers\" con 0.091.\nEs interesante notar que la fecha de alta del cliente es la característica más importante, lo que puede indicar que los clientes que se registraron hace más tiempo tienen más probabilidades de comprar nuevos productos bancarios. La actividad del cliente también es una variable importante, lo que sugiere que los clientes que tienen un historial de actividad más alto tienen más probabilidades de adquirir nuevos productos bancarios.\nOtras variables importantes incluyen la edad del cliente, el canal de entrada, la segmentación y el ingreso. También se observa que hay varias variables que tienen una importancia relativamente baja en la predicción, como el sexo, la antigüedad del cliente, el estado de residencia y la tasa de reemplazo del mes anterior.\nEn general, el análisis de Permutation Importance proporciona información valiosa sobre qué características son más relevantes para la predicción de nuevos productos bancarios, lo que puede ser útil para desarrollar estrategias de marketing y ventas más efectivas.","metadata":{}},{"cell_type":"markdown","source":"> # **6.3.4 CROSS-VALIDATION**\n![](https://dataaspirant.com/wp-content/uploads/2020/12/1-Cross-Validation.png)","metadata":{}},{"cell_type":"markdown","source":"**El paso final del planteamiento y evaluación de los modelos es analizar la generalización de estos, es decir, el comportamiento de la clasificación para diferentes divisiones de datos. Para esto, aplicamos una validación cruzada con los siguientes métodos:**","metadata":{}},{"cell_type":"markdown","source":"*** Holdout validate**\n\n*** Kfold**","metadata":{}},{"cell_type":"code","source":"clientes_modelado=pd.read_csv('clientes_modelado.csv', header=0)\nclientes_modelado.head()","metadata":{"execution":{"iopub.status.busy":"2023-04-10T22:01:27.779945Z","iopub.execute_input":"2023-04-10T22:01:27.780908Z","iopub.status.idle":"2023-04-10T22:02:08.592411Z","shell.execute_reply.started":"2023-04-10T22:01:27.780869Z","shell.execute_reply":"2023-04-10T22:02:08.591452Z"},"trusted":true},"execution_count":23,"outputs":[{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"   fecha_dato  ncodpers  ind_empleado  sexo   age  fecha_alta  ind_nuevo   \n0  20150128.0   1375586           3.0   0.0  35.0  20150112.0        0.0  \\\n1  20150228.0   1375586           3.0   0.0  35.0  20150112.0        0.0   \n2  20150328.0   1375586           3.0   0.0  35.0  20150112.0        0.0   \n3  20150428.0   1375586           3.0   0.0  35.0  20150112.0        0.0   \n4  20150528.0   1375586           3.0   0.0  35.0  20150112.0        0.0   \n\n   indrel  indrel_1mes  tiprel_1mes  ...  ind_hip_fin_ult1  ind_plan_fin_ult1   \n0     1.0            1          0.0  ...                 0                  0  \\\n1     1.0            1          0.0  ...                 0                  0   \n2     1.0            1          0.0  ...                 0                  0   \n3     1.0            1          0.0  ...                 0                  0   \n4     1.0            1          0.0  ...                 0                  0   \n\n   ind_pres_fin_ult1  ind_reca_fin_ult1  ind_tjcr_fin_ult1  ind_valo_fin_ult1   \n0                  0                  0                  0                  0  \\\n1                  0                  0                  0                  0   \n2                  0                  0                  0                  0   \n3                  0                  0                  0                  0   \n4                  0                  0                  0                  0   \n\n   ind_viv_fin_ult1  ind_nomina_ult1  ind_nom_pens_ult1  ind_recibo_ult1  \n0                 0              0.0                0.0                0  \n1                 0              0.0                0.0                0  \n2                 0              0.0                0.0                0  \n3                 0              0.0                0.0                0  \n4                 0              0.0                0.0                1  \n\n[5 rows x 39 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>fecha_dato</th>\n      <th>ncodpers</th>\n      <th>ind_empleado</th>\n      <th>sexo</th>\n      <th>age</th>\n      <th>fecha_alta</th>\n      <th>ind_nuevo</th>\n      <th>indrel</th>\n      <th>indrel_1mes</th>\n      <th>tiprel_1mes</th>\n      <th>...</th>\n      <th>ind_hip_fin_ult1</th>\n      <th>ind_plan_fin_ult1</th>\n      <th>ind_pres_fin_ult1</th>\n      <th>ind_reca_fin_ult1</th>\n      <th>ind_tjcr_fin_ult1</th>\n      <th>ind_valo_fin_ult1</th>\n      <th>ind_viv_fin_ult1</th>\n      <th>ind_nomina_ult1</th>\n      <th>ind_nom_pens_ult1</th>\n      <th>ind_recibo_ult1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>20150128.0</td>\n      <td>1375586</td>\n      <td>3.0</td>\n      <td>0.0</td>\n      <td>35.0</td>\n      <td>20150112.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>20150228.0</td>\n      <td>1375586</td>\n      <td>3.0</td>\n      <td>0.0</td>\n      <td>35.0</td>\n      <td>20150112.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>20150328.0</td>\n      <td>1375586</td>\n      <td>3.0</td>\n      <td>0.0</td>\n      <td>35.0</td>\n      <td>20150112.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>20150428.0</td>\n      <td>1375586</td>\n      <td>3.0</td>\n      <td>0.0</td>\n      <td>35.0</td>\n      <td>20150112.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>20150528.0</td>\n      <td>1375586</td>\n      <td>3.0</td>\n      <td>0.0</td>\n      <td>35.0</td>\n      <td>20150112.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 39 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"clientes_modelado.drop(columns=['fecha_dato'],inplace = True)","metadata":{"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"markdown","source":"**Debido a que nuestro conjunto de datos es demasiado grande y la memoria de la computadora no puede permitirnos ejecutar todo el conjunto de datos, solo usamos el 30% de los datos para realizar el cross-validation.**","metadata":{}},{"cell_type":"code","source":"clientes_modelado=clientes_modelado.sample(frac=0.3)","metadata":{"execution":{"iopub.status.busy":"2023-04-10T22:02:24.956825Z","iopub.execute_input":"2023-04-10T22:02:24.957622Z","iopub.status.idle":"2023-04-10T22:02:25.542157Z","shell.execute_reply.started":"2023-04-10T22:02:24.957587Z","shell.execute_reply":"2023-04-10T22:02:25.541090Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"X = clientes_modelado.iloc[:,0:16] #variables independientes\ny = clientes_modelado.iloc[:,16:38]    #target variable","metadata":{"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"from xgboost import XGBClassifier\nfrom sklearn.multioutput import MultiOutputClassifier\nfrom sklearn.metrics import precision_score\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import classification_report\nfrom sklearn.model_selection import LeaveOneOut\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.model_selection import cross_val_score","metadata":{"execution":{"iopub.status.busy":"2023-04-10T22:02:35.093532Z","iopub.execute_input":"2023-04-10T22:02:35.094264Z","iopub.status.idle":"2023-04-10T22:02:35.101777Z","shell.execute_reply.started":"2023-04-10T22:02:35.094234Z","shell.execute_reply":"2023-04-10T22:02:35.100620Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"markdown","source":"![](https://knowledge.dataiku.com/latest/_images/holdout1.png)","metadata":{}},{"cell_type":"markdown","source":"**Es una técnica que implica dividir los datos en diferentes conjuntos: un conjunto para entrenamiento y otros conjuntos para validación y prueba.**","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score\n\n#new validation set\nX_train , X_validate, y_train_hold, y_validate = train_test_split(X, y , test_size=0.1)\n\nmodel = MultiOutputClassifier(estimator=XGBClassifier())\n\nmodel.fit(X_train, y_train_hold)\n\npre = model.predict(X_validate)\naccuracy_score(y_validate, pre)","metadata":{"execution":{"iopub.status.busy":"2023-04-10T22:02:39.312202Z","iopub.execute_input":"2023-04-10T22:02:39.313409Z","iopub.status.idle":"2023-04-10T22:05:04.431125Z","shell.execute_reply.started":"2023-04-10T22:02:39.313370Z","shell.execute_reply":"2023-04-10T22:05:04.430092Z"},"trusted":true},"execution_count":29,"outputs":[{"execution_count":29,"output_type":"execute_result","data":{"text/plain":"0.576827177808945"},"metadata":{}}]},{"cell_type":"markdown","source":"![](https://knowledge.dataiku.com/latest/_images/k-fold1.png)","metadata":{}},{"cell_type":"markdown","source":"**La validación cruzada es un procedimiento de remuestreo que se utiliza para evaluar modelos de aprendizaje automático en una muestra de datos limitada.\nEl procedimiento tiene un solo parámetro llamado k que se refiere a la cantidad de grupos en los que se dividirá una muestra de datos dada. Como tal, el procedimiento a menudo se denomina validación cruzada de k-fold. Cuando se elige un valor específico para k, puede usarse en lugar de k en la referencia al modelo, como k = 10 convirtiéndose en una validación cruzada de 10 veces.\nLa validación cruzada se usa principalmente en el aprendizaje automático aplicado para estimar la habilidad de un modelo de aprendizaje automático en datos no vistos. Es decir, usar una muestra limitada para estimar cómo se espera que funcione el modelo en general cuando se usa para hacer predicciones sobre datos que no se usaron durante el entrenamiento del modelo.**","metadata":{}},{"cell_type":"code","source":"#metodo para crossvalidation\nmodel=MultiOutputClassifier(estimator=XGBClassifier())\nCV_scores = cross_val_score(model, X, y, cv=10)","metadata":{"execution":{"iopub.status.busy":"2023-04-10T15:38:01.552546Z","iopub.execute_input":"2023-04-10T15:38:01.553266Z","iopub.status.idle":"2023-04-10T16:02:19.637706Z","shell.execute_reply.started":"2023-04-10T15:38:01.553221Z","shell.execute_reply":"2023-04-10T16:02:19.636674Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"#lista de todos los entrenamiento de kfold\nCV_scores","metadata":{"execution":{"iopub.status.busy":"2023-04-10T16:03:33.187069Z","iopub.execute_input":"2023-04-10T16:03:33.187957Z","iopub.status.idle":"2023-04-10T16:03:33.194112Z","shell.execute_reply.started":"2023-04-10T16:03:33.187919Z","shell.execute_reply":"2023-04-10T16:03:33.193268Z"},"trusted":true},"execution_count":28,"outputs":[{"execution_count":28,"output_type":"execute_result","data":{"text/plain":"array([0.56506156, 0.56315748, 0.56939141, 0.57001481, 0.56533936,\n       0.57640458, 0.56666407, 0.56853425, 0.56798878, 0.57040443])"},"metadata":{}}]},{"cell_type":"code","source":"print(\"Cross validation score es  %.5f ± %0.2f\" % (CV_scores.mean(), CV_scores.std()))","metadata":{"execution":{"iopub.status.busy":"2023-04-10T16:03:37.869901Z","iopub.execute_input":"2023-04-10T16:03:37.870714Z","iopub.status.idle":"2023-04-10T16:03:37.875755Z","shell.execute_reply.started":"2023-04-10T16:03:37.870677Z","shell.execute_reply":"2023-04-10T16:03:37.874848Z"},"trusted":true},"execution_count":29,"outputs":[{"name":"stdout","text":"Cross validation score es  0.56830 ± 0.00\n","output_type":"stream"}]},{"cell_type":"markdown","source":"El valor de 0.56830 significa que la puntuación media de validación cruzada es del 56.83%, lo que indica que el modelo está obteniendo una precisión moderada en la predicción de los datos.\nLa desviación estándar (± 0.00) indica la variabilidad de las puntuaciones de validación cruzada en todas las divisiones del conjunto de datos. Como la desviación estándar es muy pequeña, podemos asumir que el modelo tiene un buen rendimiento en todas las divisiones del conjunto de datos y que la puntuación media es una buena estimación del rendimiento general del modelo.","metadata":{}},{"cell_type":"markdown","source":"**Determinamos su underfitting u overfitting**","metadata":{}},{"cell_type":"code","source":"!pip install colorama\nfrom colorama import Fore","metadata":{"execution":{"iopub.status.busy":"2023-04-10T23:01:42.382825Z","iopub.execute_input":"2023-04-10T23:01:42.383220Z","iopub.status.idle":"2023-04-10T23:01:46.777879Z","shell.execute_reply.started":"2023-04-10T23:01:42.383189Z","shell.execute_reply":"2023-04-10T23:01:46.776862Z"},"trusted":true},"execution_count":35,"outputs":[{"name":"stdout","text":"Requirement already satisfied: colorama in /usr/local/lib/python3.8/site-packages (0.4.6)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: You are using pip version 22.0.4; however, version 23.0.1 is available.\nYou should consider upgrading via the '/usr/local/bin/python -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"def print_scores(model ,X_train , y_train, predictions , cv_splites=10):\n    \n    print(Fore.BLUE , \"El promedio de score en el train es  %.5f\" % model.score(X_train, y_train))\n\n    #cross validation\n\n    CV_scores = cross_val_score(model, X_train, y_train, cv=cv_splites)\n    \n    print(Fore.BLUE ,\"Los scores del cross validation son: \\n\",CV_scores)\n    print(Fore.BLACK ,\"El score minimo es %.3f\" % min(CV_scores))\n    print(Fore.BLACK ,\"El maximo score es %.3f\" % max(CV_scores))\n    print(Fore.BLACK ,\"Cross validation score es  %.5f ± %0.2f\" % (CV_scores.mean(), CV_scores.std()))\n    print(Fore.RED ,\"El test score es  %.5f \" % accuracy_score(y,predictions))","metadata":{"execution":{"iopub.status.busy":"2023-04-10T23:01:50.156751Z","iopub.execute_input":"2023-04-10T23:01:50.157912Z","iopub.status.idle":"2023-04-10T23:01:50.166051Z","shell.execute_reply.started":"2023-04-10T23:01:50.157866Z","shell.execute_reply":"2023-04-10T23:01:50.165178Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"model=MultiOutputClassifier(estimator=XGBClassifier())\nmodel.fit(X, y)\n\npredictions = model.predict(X)\nprint_scores(model, X, y, predictions)","metadata":{"execution":{"iopub.status.busy":"2023-04-10T23:01:53.478323Z","iopub.execute_input":"2023-04-10T23:01:53.478632Z","iopub.status.idle":"2023-04-10T23:29:26.997116Z","shell.execute_reply.started":"2023-04-10T23:01:53.478601Z","shell.execute_reply":"2023-04-10T23:29:26.996063Z"},"trusted":true},"execution_count":38,"outputs":[{"name":"stdout","text":"\u001b[34m El promedion de score en el train es  0.60279\n\u001b[30m Los scores del cross validation son: \n [0.56420446 0.57149536 0.56728746 0.57188498 0.56985896 0.57585911\n 0.56510559 0.57266423 0.56728746 0.57040443]\n\u001b[30m El score minimo es 0.564\n\u001b[30m El maximo score es 0.576\n\u001b[33m Cross validation score es  0.56961 ± 0.00\n\u001b[31m El test score es  0.60279 \n","output_type":"stream"}]},{"cell_type":"markdown","source":"**Observaciones:**\n\nSe observa que el modelo tiene un promedio de score en el train de 0.60279, lo cual indica que el modelo está aprendiendo de manera efectiva los patrones de los datos de entrenamiento.\nEn cuanto a los scores del cross validation, se observa una variación entre 0.564 y 0.576, lo que indica que el modelo puede tener cierta variabilidad en su desempeño dependiendo de los datos con los que se esté evaluando.\nEl score de cross validation promedio es de 0.56961 con una desviación estándar de 0.00, lo que indica que el modelo es consistente en su desempeño en diferentes subconjuntos de datos.\nPor último, se observa que el score en el conjunto de test es de 0.60279, lo que indica que el modelo tiene un buen desempeño en la generalización a datos nuevos. En resumen, el modelo parece estar funcionando de manera adecuada y se está generalizando bien a datos nuevos.","metadata":{}}]}